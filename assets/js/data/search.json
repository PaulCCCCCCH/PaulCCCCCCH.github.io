[ { "title": "On Encapsulating HTTP Requests with React Hooks", "url": "/posts/frontend-react-request-with-hooks/", "categories": "Software Development, Frontend", "tags": "notes, experience, tutorials, software engineering, react, frontend, english", "date": "2022-06-20 14:00:00 -0400", "snippet": "IntroductionThe Position of Hooks in the Big PictureIn my opinion, the key goal of Scaffolding in software engineering is to simplify two things: development and maintenance. A great way to achieve this goal is through logic sharing. By sharing logic, you write less code during development, and locate bugs more quickly during maintenance.This is the direction to which frontend development world is evolving. With the introduction of frontend frameworks, people are allowed to define and reuse DOM elements. Also, we are able to use pre-defined and shared data-binding and rendering logic, which all main-stream frontend frameworks provide. Recently, logic sharing is pushed even further. For example, Vue3.js introduced Composition APIs to allow grouping functions handling the same data objects together, ignorant of which component is using them, and React introduced react Hooks to allow easier sharing of logic around certain states.For this post, we will focus on React and Hooks.My Understanding of HooksFrom my understanding, React Hooks allows a more flexible way of handling state. state has been around since React was born, but the handling (e.g., updating and rendering) of a state seems to be privately owned by a component, which cannot be shared easily. Imagine you have two components, each having some states and hanlder functions for that state. Both components use stateA.Component X { stateA, stateB, handlersForStateA, // can be 1000 lines of code handlersForStateB, render: &amp;lt;div&amp;gt; &amp;lt;DOM1 state={stateA} /&amp;gt; &amp;lt;DOM2 state={stateB} /&amp;gt; &amp;lt;/div&amp;gt;} Component Y { stateA, stateC, handlersForStateA, // can be 1000 lines of code handlersForStateC, render: &amp;lt;div&amp;gt; &amp;lt;DOM1 state={stateA} /&amp;gt; &amp;lt;DOM2 state={stateC} /&amp;gt; &amp;lt;/div&amp;gt;}How would you share the logic here? Without Hooks, you have to share logic with a helper component. The helper component looks like thisComponent Helper { stateA, handlersForStateA, render: &amp;lt;DOM1 state={stateA} /&amp;gt;}Then, you can simply change component X and Y toComponent X { // No need for state A here anymore, may save 1000 lines of code stateB, handlersForStateB, render: &amp;lt;div&amp;gt; &amp;lt;Helper /&amp;gt; &amp;lt;DOM2 state={stateB} /&amp;gt; &amp;lt;/div&amp;gt;}Component Y { // No need for state A here anymore, may save 1000 lines of code stateC, handlersForStateC, render: &amp;lt;div&amp;gt; &amp;lt;Helper /&amp;gt; &amp;lt;DOM2 state={stateC} /&amp;gt; &amp;lt;/div&amp;gt;}Thus, we extracted logic for stateA and freed ourselves from repeating that 1000 lines of code. However, what if we want to render stateA differently for component X and Y? For example, I want to wrap stateA in a popup in component X, and want to wrap stateB in a table in component Y. How do I achieve this? The answer is, there is no elegant way of doing this other than creating more helper components for encapsulation.Component PopupHelper{ render: &amp;lt;Popup&amp;gt; &amp;lt;Helper /&amp;gt; &amp;lt;/Popup&amp;gt;}Component TableHelper{ render: &amp;lt;Table&amp;gt; &amp;lt;Helper /&amp;gt; &amp;lt;/Table&amp;gt;}Then, we use PopupHelper in Component X and TableHelper in Component Y. This is frustrating, because what we really want to share the state part (state + handlers), but we are forced to create a shared component (state + handlers + rendering).This is where Hooks comes into rescue. A hook defines a state (or a set of states) and the logic regarding that state. It is useful to think of it as a component without a rendering logic. With hooks, you can easily decouple state logic with view, thus allowing more flexible logic sharing.Hooks is a powerful tool for logic sharing. In this post, we investigate specifically how we encapsulate the logic around sending HTTP requests to allow the most sharing in the most elegant way possible.Problem SetupRequest with StateAll HTTP requests need to read from several states, for example, authentication state, frontend side throttling state, and server root url (suppose the user can select which backend to talk to). We assume all state information is aggregated to one object called apiState can be read from one useApiState call.HTTP Request LibraryImagine we have a library to help us send HTTP request, which we can use aslib.get(url: string, state: object) // For Get requestslib.post(url: string, data: object, state: object) // For POST requestsBoth functions return a Promise object, and you can use await or .then() to resolve. We omit other request types as they are not very different from these two.RESTful API EndpointsWe assume the endpoints follow RESTful API styles. For illustration purposes, we consider the following three endpoints we need to cover Type 1, URL only, e.g. GET https://example.com/user Type 2, URL with path parameters, e.g. GET https://example.com/user?first=paul&amp;amp;last=chen Type 3, URL with path parameters and request body, e.g. POST https://example.com/user with data = {first: paul, last: chen}GoalThe goal is to encapsulate HTTP requests, so that we don’t need to worry about all the HTTP intricacies in the components. For example, if I want to fetch user data from the server, I should be able to call them like normal functions, e.g.const users = await fetch_user(param1, param2);or thislet usersfetch_user(param1, param2, (res) =&amp;gt; users = res.data, // on success (err) =&amp;gt; users = [] // on error)or anything equivalent. I shouldn’t be assembling request url / headers, etc in my component. I omitted the handling of loading and error state and other things that do not add complexity to our design.A Naive Approach (Pure Javascript)I used to work mostly with Vue.js and this solution is what I used first. This approach is framework-agnostic. All implementations are based on pure JavaScript.I first create a generic requester for each request typesconst sendGETRequest(url) { const apiState = getApiState() // Problem: how do we get state here? return lib.get(`${apiState.server_root}/${url}`, apiState)}const sendPOSTRequest(url, requestBody) { const apiState = getApiState() // Problem: how do we get state here? return lib.get(`${apiState.server_root}${url}`, requestBody, apiState)}Then, we encapsulate all API endpointsconst APIGetUsers() { return sendGetRequest(&quot;/user&quot;)}const APIGetUser(first, last) { return sendGetRequest(`/user?first=${first}&amp;amp;last=${last}`)}const APIPostUser(first, last) { return sendPostRequest(`/user`, {first, last})}Then, we can make these calls anywhere in our program, as if they are plain old helper functions. The problem is, how do we get the apiState here? We cannot use useApiState, because these functions are neither functional components nor react hooks. We could read from localStorage or Redux storage, but this means you cannot control the scope of the state (they are always global). For example, it becomes impossible for you to use two different apiState in two components. Plus, this does not feel React at all.What Most Bloggers Suggest (w/ Hooks)As I moved from Vue.js to React.js, I was amazed by Hooks. It reminds me of the good old days when I was using Haskell , where a huge amount of states were chained together and worked like a miracle (yes, sadly I have to admit it is the feeling of functional programming that attracts me, and React.js is not really more elegant than vue.js in my opinion). Anyway, I feel the urge to explore a better, more “reacty” way of encapsulating HTTP requests. Here is what most bloggers suggest (you can see a bunch of them by searching for react useApi hook).const useApi(url) { const apiState = useApiState() // use `result` state to record server&#39;s response for this request const [result, setResult] = useState() useEffect(() =&amp;gt; { lib.get(`${apiState.server_root}/${url}`) .then((res) =&amp;gt; setResult(res.data)) .catch((err) =&amp;gt; setResult(null)) }, [url]) return [result]}In a component, we can do the followingfunction SomeComponent { const [data] = useApi(&#39;/user&#39;) return &amp;lt;DOM1 state={data}&amp;gt;}With this approach, we can encapsulate all HTTP request related logic in the useApi call. This looks nice, but it is to restricted because: It does not support path parameters, and there is no way to change the url of the request. Suppose we want to call https://example.com/user?first=paul&amp;amp;last=chen with first and last parameters from input boxes, this approach simply can’t do this. For the same reason, POST requests with a dynamic requestBody are not supported. By defining useApi this way, we explicitly assume the purpose of this request is to retrieve some data and stored in result state. However, some requests may require an additional callback (e.g., jump to another page, change another variable), which is not supported by this design. The request is sent at loading time. There is no way to manually sending the request again (e.g., when the user clicks a refresh button) setResult is not exposed to the outside world. The only way to update the state is through sending a request and getting a new result. If you want to allow changing the state to trigger a re-render of a page, you have to use ugly hacks.Sadly, the top 10 tutorials I found on encapsulating HTTP calls with Hooks all stopped here. Even the established libraries (e.g., react-use-api) fail to address all of the problems above. This keeps me thinking, isn’t this scenario so common that there should have been a very good solution out there?Building on Solutions From Others (w/ Hooks)To address the issues mentioned above, I tweaked (if not reformulated entirely) previous solution. Here is a list of things I did.Allow Triggering Any TimeInstead of wrapping lib.get() in useEffect call, I wrap it in a function and expose it to the caller of useApi. This allows triggering the request any time.const useApi(url) { const apiState = useApiState() const [result, setResult] = useState() const sendRequest = () =&amp;gt; { // Changed from useEffect to this to allow triggering any time lib.get(`${apiState.server_root}/${url}`) .then((res) =&amp;gt; setResult(res.data)) .catch((err) =&amp;gt; setResult(null)) } return [result, sendRequest]}Allow Dynamic URL and DataWe accept an url parameter at the time of sending the request, instead of calling the hook. This allows sending requests with dynamic parameters decided at run time. const useApi() { // removed url parameter here const apiState = useApiState() const [result, setResult] = useState() // put url parameter here so that url can be dynamically changed at send time const sendRequest = (url) =&amp;gt; { lib.get(`${apiState.server_root}/${url}`) .then((res) =&amp;gt; setResult(res.data)) .catch((err) =&amp;gt; setResult(null)) } return [result, sendRequest] }Do Not Define State InsideAs we mentioned above, defining a result state inside makes the useApi hooks much less generic. Instead, we require the caller of sendRequest to provide callback functions, which allows the most customization. If the caller wants to define a state, it can still define it in a component, and update it in the callback. This logic can also be shared across multiple components easily just like other logic.const useApi() { // we no long need `result` state const apiState = useApiState() // accept success and fail callbacks here const sendRequest = (url, onSucc, onFail) =&amp;gt; { lib.get(`${apiState.server_root}/${url}`) .then((res) =&amp;gt; onSucc(res)) .catch((err) =&amp;gt; onFail(err)) } // we no longer expose a `result` state return [sendRequest]}Supporting Multiple Request TypesWe can easily extend this template to support multiple request types.const useApi() { const apiState = useApiState() // accept an additional requestType and (optional) requestBody parameter // send different request accordingly const sendRequest = (url, requestType, onSucc, onFail, requestBody) =&amp;gt; { let promise; switch requestType { case GET: promise = lib.get(`${apiState.server_root}/${url}`) break; case POST: promise = lib.post(`${apiState.server_root}/${url}`, requestBody) break; case DELETE: // ... all other types } promise.then((res) =&amp;gt; onSucc(res)) .catch((err) =&amp;gt; onFail(err)) } return [sendRequest]}Additional Encapsulation For Each End Point, Good To Go!The useApi is done. We now need to consider how to use useApi. The caller (i.e., the components) will need to provide parameters to sendRequest function:const sendRequest = (url, requestType, onSucc, onFail, requestBody) =&amp;gt; { ... }Recall that our goal is to make the components ignorant of the intricacies of HTTP requests, so we don’t want to do this in the component logicconst [sendRequest] = useApi()const url = `/user?first=${userInputFirst}&amp;amp;last=${userInputLast}` // construct endpoint urlconst sendRequest(url, GET, ...)This to me is too ugly, because you are hard-coding the request URL template inside a component. You probably need to hard-code it multiple times if multiple components use this endpoint. Thus, let’s do an encapsulation for this endpoint.const useAPIGetUser(onSucc, onFail) { const [sendRequest] = useApi() const sendGetUsersRequest = (first, last) =&amp;gt; { const url = `/user?first=${first}&amp;amp;last=${last}` sendRequest(url, GET, onSucc, onFail) } return [sendGetUsersRequest]}Then, in any component, all we need to do isconst [sendRequest] = useAPIGetUser(onSucc, onFail) // define callbackssendRequest(userInputFirst, userInputLast) // send the requestThere is no HTTP Request related stuff here. All the component knows is that it calls some function and updates its states with callbacks defined within the component. We can simply define one useAPIxxx hook for each API endpoint, and put them all in one folder, so that everything related to sending requests will be there.Closing RemarksThis has been the most elegant and clean way to encapsulate HTTP calls that I can think of (after all the mind struggles and research). However, it does lead to what’s known as callback hell: the component is filled with arrow functions (because of the excessive use of callbacks), and the logic is a bit weird to follow. We could easily change our template to async/await style of sending requests: you can just return the result of the inner most lib.get out layer by layer instead of calling then on it. Personally I think it’s OK to leave it as callbacks as it encourages me not to write nested code, which is usually an indicator of bad code design.To implement useApiState, you can use different methods to store different states. For example, use login status may be stored with React Context API and LocalStorage, and throttling information can be handled with a state manager such as Redux." }, { "title": "CMU第一学年进化日志", "url": "/posts/cmu-sem2/", "categories": "Writing", "tags": "CMU, writing, personal, chinese", "date": "2022-05-06 22:00:00 -0400", "snippet": "Forbes沿街的树，秃了一个冬天，近来都慢慢得绿了回来；走去学校的时候，阳光已经能逼得人微微出汗。这夏天的感觉，跟我来匹兹堡的第一天一模一样。季节来了一个轮回，但是自己的心态以及周围的人和事，已经处在完全不同的河流，于是又老气横秋地感慨起来。想着反正诸事已经暂告段落，不如总结一下这一年的变化，顺便填一填年久失修的blog。关于坚持初心最初，我来读master，尤其是在美国，在CMU读master的核心原因是这些： 把本科落下的基础知识尽量多补一些回来 有一定深度地尝试各个领域，方便未来做出informed decision 通过各种合作，尽量多获取上乘的connection，积累人脉 确认自己要不要做学术其实我的focus在探索和积累资源。我并没有要求自己拿到多高的GPA。至于发paper、拿公司offer，这些虽然要做，却也不是目的本身。但是，在peer pressure之下，思路很容易就被模糊掉了：我会为了争一点分数做出marginal gain很低的努力，会为了刷题拒绝参加例如创业周末的比赛，会因为实习没有拿到大厂offer而慌张。对此常见的诊断是羊群效应，但是对于惯于离经叛道的我并不适用。我认为，本质上还是对自己能力自信不足导致的：不自信导致想要证明自己的能力，另一方面又太在意他人的评价，认为只有公认的，且有明确的成功/失败界限的任务才是能力的证明，所以导致，当大家在做这样的事情的时候，我迫切地也想要达成，并且想要做得更好。这在短期确实可以带来心理上的满足，但是长期来看对我没有任何好处。我一直隐约意识到自己的这个弱点，现在终于把它明确地定义了出来，算是解决了一半。我仍然希望争强好胜的feature被保留，只不过在自我评价的时候，分给外界的权重能小一些。关于心态“出了学校，我可能就是最菜的”。这样的心态，我维持了整个本科四年。虽然一直有心理准备，但是真的发现自己很菜的时候，还是相当不适的。周围人的眼睛里，都闪烁着聪明人才有的光；在很多方面，想要match上大家的level是一件非常struggle的事情。更可怕的是，同专业的好多同学，本科并不是计算机专业。他们在其它领域的知识储备远远超过我，然而在计算机领域，我们知道的一样多；还有一些同学，一样的年纪，已经发表过十多篇论文，或者已经从高赞的开源项目积累了巨量工程经验。放在以前，我可能会开始自卑，因为他们in general是更“好”的人。这里可能要引用一下我之前的理论： 人很大程度上是可以被一个或少数几个scalar解释的：每个人能每个方面的能力强弱都可以用一个数值去衡量，而这些数值，都是以这（几）个核心scalar为均值，按照某个概率分布生成的。他们在这些方面如此突出，大概率意味着他们的scalar数值很高，所以他们如果做其它事情，也大概率会做得非常好。这和我们的observation相符：优秀的人，大概率做什么事情都很优秀。换句话说，我可能做大部分事情都不如他们，我是可以被替代的“次品”。整个本科阶段，我都在用这个理论自我PUA。在CMU这一年（也许是之前创业的那一年），我开始接受事实，并且有意识地寻找解决办法。于是，我又重新思考这个理论的implication，观点逐渐转向difference over superiority。我不否认superiority的存在，有的人就是什么都比较容易做得更好。但是，因为存在非常非常多可能的方面，所以对于每一个人，应该存在这样一些方面，满足以下条件 在这些方面上，这个人的数值恰好都还不错 这些方面可以组成一个真实存在的，或者至少可行的任务 在这个任务上，这个人的能力排名达到顶尖水平只要选择足够多的优势方面，第三点应该是很容易达到的。可能真正困难的是在第二点：很多人的优势方面由于不甚相关，很难构成明显可行的任务，所以在决定做什么这件事上要付出更多的精力，也通常表现出不那么优秀的样子。对我来说，虽然我没有在任何方面达到顶尖（也许除了身体的平衡能力？hhhh），不过，我数值较高的方面还是比较多的。所以我可能要尽可能选择那些涉及方面广的任务。可能创业的确是适合我走的路。即便不是创业，我可能也要优先选择干细胞类型的工作。关于科研来CMU读master的，多多少少都有些科研的念想吧。我其实也一直纠结，到底要不要做学术。为了回答这个问题，我本科做了挺长时间的NLP research，毕业项目做了NLP+RL方向；来CMU之后，我又做了好几个Multimodal的research项目。从一些角度看，我还是挺适合做research的： 我是放散型思维的人，比较喜欢把知识串联起来，触类旁通，可以很愉快地探索各个领域，接触各种idea，然后做总结。 我是灵感驱动类型的，所以开脑洞想idea的过程还是挺享受的，并且一定程度上擅长。 足够卷，而且能忍。当然，也有很多劝退的因素： 如果把我的大脑比作电脑，那么我的内存极小。对于定义得比较好、不那么开放的问题，如果我们把它看作是搜索的过程，我能同时keep track的搜索节点很少，这就意味着寻找解题思路非常困难，所以无缘奥数、ACM这一类活动，科研一样也不行。 我可能有轻度强迫症。在探索阶段，实验代码通常很凌乱，毫无设计感，这让我非常抓狂。我也很讨厌实验的过程，会觉得无聊。 科研的挫败感太强，即便是很好的idea，也很难让它work；而我对挫败感的抵抗力又太低，一旦感受到挫败，虽然会在责任心驱使下继续工作，但是如果不是从灵魂深处对结果抱有期待，就很容易变成应付。正反两方僵持不下。最后，这学期上的LP的11-877 Advanced Multimodal Machine Learning，终于把我结结实实地劝退了。这门课每周要读paper，写note，在每周的seminar上交流，并且有个持续一学期的research project。我深刻地理解了，真正的科研人和我这样的人之间，其实隔了一座山。只不过，这山里并不是什么魑魅魍魉艰难险阻，而是一点一滴的兴趣化成的砂石、草木，虫鱼鸟兽。科研的要求很低，它只要求兴趣；科研的要求也极高，它要求忘我的兴趣，这种东西，你要是没有，你就是没有。关于自律一年创业+CMU俩学期，我的体重已经从将近70kg跌成不到60kg（最近涨回来点）。从腹肌判断体脂可能变化不大，但是手臂啥的已经纤细得像柳条了（淦）。虽然推说是没时间，但是一周封顶也就五个小时的时间，不可能真的拿不出来。不锻炼是会形成惯性的。不锻炼、碎片化地消耗时间、拖延、晚睡、不好好吃饭、喝可乐等等，这些都会形成惯性，一旦形成，很难停下来。其实我也是有成功逼停的案例的：刚来美国的时候，喝可乐和果汁上瘾。感觉那段时间喝的饮料比这辈子加起来都多，后来是通过强行忍住戒掉的。其它问题，也是类似地强行“动态清零”。但是这种办法并不generalizable。没有公式化的方法，光靠意志力，很多更严重的问题无法解决，或者复发严重。可能得再研究一下，也许老弟也会需要。其它不那么功利的事情 越来越不做饭了，顿顿在外面吃。我反正是对CMU附近的食物赞不绝口，建议那些挑三拣四的同学们去英国非伦敦地区留学一年，体验一下底层人民的艰辛。 沉迷爵士。很喜欢那种玩世不恭的调调，感觉非常解压，并且深深震撼于各种和弦的代替和变化，还有各种音阶的即兴。有在好好研究和练习。 第二学期前中期出现了一点情绪上的问题。虽然也难过了很久（导致midterm炸裂？），但是算了一下，这次处理的效率是上一次的将近20倍。突飞猛进了属于是。 美国的高速路比国内差好多，但是车速却更快。感觉挺危险的。不过开几趟下来，车技已经大有进步。这是在国内开多久都达不到的。 开始对马尔库塞感兴趣，但是似乎找不到对他的解析和导读之类的，只能抱着原著硬啃。感觉比起马克思，他的观念更合理一些。" }, { "title": "Prelude", "url": "/posts/prelude/", "categories": "Writing", "tags": "changes, writing, personal, english", "date": "2021-10-25 22:12:00 -0400", "snippet": "Finally found a chance to get this thing done: set up a formal version of my website and publish it.I have tried this multiple times over the years. I have designed and built up my own theme and wrote all the scripts with detailed docs. But as soon as I finished building the pipeline, I realized there wasn’t much I wanted to share with people after all. In some sense, it was the process of building the website that I enjoyed, not maintaining it or creating content. I do takes notes and write things (a lot), but I was not so comfortable sharing them.Yet, this time, I feel the urge that I need a place to demonstrate myself. Making up my mind really makes a significant difference: the website was ready in just 2 hours, because the purpose has changed from building it on my own to rapidly creating a space for exposure (and that I’m now at CMU, which means every minute I spent on this came from my sleep time).Anyway, I will start migrating my content to this website (either public or private) as much as I can. See you in the future!" }, { "title": "Robustar", "url": "/posts/robustar/", "categories": "Project", "tags": "deep learning, software engineering, pytorch, english", "date": "2021-10-23 04:00:00 -0400", "snippet": "Place holder here" }, { "title": "Backend Recipe for Beginners (Springboot + MyBatis)", "url": "/posts/backend-spring/", "categories": "Software Development, Backend", "tags": "notes, experience, tutorials, software engineering, springboot, backend, chinese", "date": "2021-05-12 04:00:00 -0400", "snippet": "I wrote this for the m5-201 course, which aims at preparing new programmers for real full-stack development and tech team leader roles.后端开发规范在开始着手做以下内容之前，请务必先把产品的逻辑梳理得井井有条。该用到 UML、该写文档的地方，绝对不要节省笔墨和时间，哪怕为此稍微耽误了开发进度。也不能因为使用了 敏捷开发，而忽略明确需求的重要性。在反复确认准备工作已经完成之后，我们进入开发流程。本篇文档着重描述基于 SpringBoot 的后端开发规范。为了方便沟通，我们以一个申研信息分享论坛的项目为例，按照后端开发的时间顺序，逐一梳理开发过程中需要注意的规范。数据库的设计需求明确之后，首先要进行开发的是数据库。在分析完申研信息分享论坛的项目需求之后，我们大概可以明确，数据库要储存哪些信息。我们例举其中比较重要的几个数据表： offer 表：记录所有的 offer，信息包括来自哪所学校、收到的时间、有无奖学金等等。 thread 表：记录论坛里所有的帖子，信息包括发布者、发布时间、帖子内容等等。 user 表：记录所有的用户信息，信息包括用户名、密码的 hash、昵称等等。设计数据库时，可以尽量参照阿里数据库设计规范。可以先通读一遍，有个大致印象；在设计完数据库之后再一一对照纠错。接口规范在不那么复杂的项目中，接口与数据库的表一般是高度对应的。除了一些后台使用的，或为了表示多对多关系的表之外，一般每个表都会对应一系列的 CRUD 操作 —— Create (创建), Read (读取), Update (更新) 和 Delete (删除)。上面提到的 thread 表（记录所有帖子信息的）就是如此。对于一个论坛来说，我们需要创建新帖子、读取一系列/某个帖子、更新一个帖子、删除一个帖子。对于 offer 和 user，我们也要进行一样的操作。每一个接口，对应一个 url 以及一些参数。在设计的时候，我们希望遵循时下流行的 RESTful API 规范。以 thread 相关接口的设计为例，假定我们的服务器 ip 地址为 10.20.30.40： 创建一个新帖子：用 POST 请求 https://10.20.30.40/threads 读取所有帖子：用 GET 请求 https://10.20.30.40/threads 读取一个 id 为 1115201 的帖子：用 GET 请求 https://10.20.30.40/threads/1115201 更新一个 id 为 1115201 的帖子：用 PUT 或 PATCH 请求 https://10.20.30.40/threads/1115201 删除一个 id 为 1115201 的帖子：用 DELETE 请求 https://10.20.30.40/threads/1115201 列出一个 id 为 1115201 的帖子的所有回复：用 GET 请求 https://10.20.30.40/threads/1115201/posts 删除一个 id 为 1115201 的帖子中，id 为 1005101 的回复：用 DELETE 请求 https://10.20.30.40/threads/1115201/posts/1005101可以看出，光从我们请求的 url，并不能看出我们进行的是 CRUD 中的哪种操作（前两条功能完全不同的请求甚至有一模一样的 url）。我们是通过请求不同的请求方法，达到不同的目标的。换句话说，请求的 url，只提供操作对象的信息，而不定义操作的种类。使用 SpringBoot 代码实现出来，应该是下面这样（注意其中函数的返回类型均为 CommonResult，这我们会在 数据的包装 中讲到）：// 第一个接口，创建一个帖子@PostMapping(&quot;/threads&quot;)public CommonResult&amp;lt;String&amp;gt; createThread(@RequestBody Thread thread) {...}// 第二个接口，读取所有帖子@GetMapping(&quot;/threads&quot;)public CommonResult&amp;lt;List&amp;lt;Thread&amp;gt;&amp;gt; getThreads() {...}// 第三个接口，读取指定 id 的帖子@GetMapping(&quot;/threads/{id}&quot;)public CommonResult&amp;lt;Thread&amp;gt; getThread(@PathVariable BigInteger id) {...}// 第四个接口 (只写了 PUT)，更新一个帖子@PutMapping(&quot;/threads/{id}&quot;)public CommonResult&amp;lt;String&amp;gt; updateThread(@PathVariable BigInteger id, @RequestBody Thread thread) {...}// 第五个接口，删除指定 id 的帖子@DeleteMapping(&quot;/threads/{id}&quot;)public CommonResult&amp;lt;String&amp;gt; deleteThread(@PathVariable BigInteger id) {...}// 第六个接口，列出指定 id 的帖子的所有回复@GetMapping(&quot;/threads/{threadId}/posts&quot;)public CommonResult&amp;lt;List&amp;lt;Post&amp;gt;&amp;gt; getThreadPosts(@PathVariable BigInteger threadId) {...}// 第七个接口，删除指定 id 的帖子下的指定 id 的回复@DeleteMapping(&quot;/threads/{threadId}/posts/{postId}&quot;)public CommonResult&amp;lt;String&amp;gt; deleteThreadPost(@PathVariable BigInteger threadId, @PathVariable BigInteger postId) {...}数据的包装以 user 这个表为例。我们的数据库中，可能记录了这些数据： id: 用户 id user_name: 用户名 user_psw_hash: 用户密码的 hash display_name: 用户昵称 user_level: 用户等级 user_exp: 用户经验值对应地，我们会创建一个 User 类，对应这个表：public class User { private BigInteger id; private String userName; private String userPswHash; private String displayName; private int userLevel; private int userExp; // Getters and setters...}在前端，当用户 A 点开 用户 B (id 为 5201) 的个人主页，需要向后端索要用户 B 的信息。按照 RESTful 的接口设计风格，需向 https://10.20.30.40/users/5201 发送一条GET 请求。然后，我们在 Mybatis 的 Mapper 里写这样的查询函数：public interface UserMapper { @Select(&quot;SELECT * FROM user WHERE id = #{userId}&quot;) User findById(@Param(&quot;userId&quot;) String userId);}然后，在 UserController 中这样处理请求：/********************* 这样写其实不可取！！！！********************/@GetMapping(&quot;/users/{id}&quot;)public User getUser(@PathVariable BigInteger id) { return userMapper.findById(id);}这样，在收到用户请求时，相当于运行了下面的查询，然后把结果返回给前端。SELECT * FROM user WHERE id = 5201但是，这样会有问题：用户 A 在前端会接收到 用户 B 在数据库中的全部信息，包括 user_name 和 user_psw_hash。这两个信息只是后台登录用的，根本就不应该让用户看到，不然会造成严重的安全问题。我们只能展示前端需要的信息。所以，我们得新创建一个类 UserVO，这是专门面对用户的 User 类，包含的信息都是用户可以看的：public class UserVO { private String displayName; private String userLevel; private String userExp; // Getters and Setters...}VO 即 View Object，是专门返还给前端用的。UserVO 和 User 比起来，少了 userName 和 userPswHash。这些是用户登录的时候用的东西，不能给其它用户看。于是，我们可以在 UserController 里这样处理请求：@GetMapping(&quot;/users/{id}&quot;)public User getUser(@PathVariable BigInteger id) { // 先去数据库找 user User user = userMapper.findById(id); // 创建 userVO，把 user 中不敏感的数据拿出来，给到 userVO UserVO userVO = new userVO(); userVO.setDisplayName(user.getDisplayName()); userVO.setUserLevel(user.getUserLevel()); userVO.setUserExp(user.getUserExp()); // 把不包含敏感信息的 userVO 返回给用户 return userVO;}但是，这样仍然不够完美。我们并没有考虑到 Error 的可能性（比如查询的用户不存在）。并且，我们回复的消息过于 干货 了：除了数据内容之外，啥也没有。这对前端来说非常不友好。我们建议大家使用 CommonResult（点击这里下载它的代码） 对返回值进行封装，这样任何的返回消息，都会是以下格式：{ &quot;code&quot;: 200, // 200 是成功，其它可能的有 500、404、401 等等。 &quot;message&quot;: &quot;some text here&quot;, // 除了数据之外，有哪些信息要展示给用户的（尤其是在出错的情况下）。 &quot;data&quot;: ... // 这才是数据。如果出错的话，可以设置成 null，然后在 message 里给出错误原因。}于是，上面的代码变成：@RestControllerpublic class UserController { @Resource // 告诉 SpringBoot，如何初始化这个变量，这样就不用在 constructor 里去初始化了。 private UserMapper userMapper; @GetMapping(&quot;/users/{id}&quot;) public CommonResult&amp;lt;UserVO&amp;gt; getUser(@PathVariable BigInteger id) { // 先去数据库找 user，跟之前一样，但是考虑数据库错误的情况 User user; try { user = userMapper.findById(id); } catch (Exception e) { return CommonResult.failed(&quot;数据库错误。&quot;); } // 如果 user 找不到的话： if (!user) { return CommonResult.failed(&quot;操作失败，用户未找到。&quot;); } // 这跟之前一样 UserVO userVO = new userVO(); userVO.setDisplayName(user.getDisplayName()); userVO.setUserLevel(user.getUserLevel()); userVO.setUserExp(user.getUserExp()); // 返回封装好的 result return CommonResult.success(userVO); }}这样是不是相当优雅？其实还是不够。因为我们把过多的功能放在了 Controller 类里，这很不好，如果接口很多，会导致这个类肥硕无比。并且，这样做的复用性极差：因为我们在 Controller 里定义的函数，返回的都是封装好的 CommonResult，是专门对外的，内部重复利用 Controller 里面的函数，还要把返回值的封装拆开，这非常蠢；另外，Controller 里函数的内容，都是完整的请求处理逻辑，而不是像积木那样很独立、很割裂的功能模块，本来就很难有可以重复利用的地方。如何进一步优化呢？这是我们下一节要讲的内容。处理流程仍然以获取用户信息的请求为例（向 https://10.20.30.40/users/5201 发送 GET 请求）。目前为止，我们处理用户请求的逻辑是这样： UserController 的 user/{id} 这个 url 上接到请求。 UserController 调用对应的函数 getUser()。 getUser 使用 userMapper 查找数据库。 getUser 创建 UserVO 对象，把可以给用户看的属性从 User 对象里提取出来，塞到 UserVO 对象里。 UserController 把 UserVO 塞到 CommonResult 里，返回给用户。之前提到，getUser 这个函数做的事情太多了，也不能被重复利用。我们需要再设计一个类 UserService，里面写一些可以被重复利用的逻辑（就像为自己打造各种形状的小积木），这样 UserController 就不需要写很多代码，只需要把想用的积木从 UserService 里拿出来，拼一下就可以了。具体地，对于 UserController，我们写一个 UserService，像下面这样：@Servicepublic class UserService throws Exception{ @Resource private UserMapper userMapper; public User getUserById(BigInteger id) { User user; try { user = userMapper.findById(id); } catch (Exception e) { throw new Exception(&quot;Database error&quot;, e); } // 如果 user 找不到的话： if (user == null) { throw new NotFoundException(&quot;User not found&quot;); } return user; } public static UserVO UserToUserVO(User user) { UserVO userVO = new userVO(); userVO.setDisplayName(user.getDisplayName()); userVO.setUserLevel(user.getUserLevel()); userVO.setUserExp(user.getUserExp()); return userVO }}我们注意到，把 User 转成 UserVO 这样的操作会经常用到，所以我们写一个函数，方便复用。这样写好之后，我们的 UserController 就变成：@RestControllerpublic class UserController { // 用 UserService 去替换之前的 UserMapper // 这样 UserController 就没有权限去直接操控数据库了，一切处理都需要通过 UserService 完成 @Resource private UserService userService; @GetMapping(&quot;/users/{id}&quot;) public CommonResult&amp;lt;UserVO&amp;gt; getUser(@PathVariable BigInteger id) { // 先去数据库找 user，跟之前一样，但是考虑数据库错误的情况 // 这跟之前一样 try { User user = userService.getUserById(id); } catch (NotFoundException e) { return CommonResult.failed(e.getMessage()); } catch (Exception e) { e.printStackTrace(); // 这个错误信息对 debug 非常有用，要 print 出来 return CommonResult.failed(e.getMessage()); } UserVO userVO = UserService.UserToUserVO(user); // 返回封装好的 result return CommonResult.success(userVO); }}这样处理之后，上述的流程就变成： （不变）UserController 的 user/{id} 这个 url 上接到请求。 （不变）UserController 调用对应的函数 getUser()。 （新） UserController 里的 getUser() 调用 userService.getUserById() 函数。 （新） 在 UserService 的 getUserById 函数中，使用 userMapper 查找数据库，返回 User 对象。 （新） 在 UserService 的 getUserById 函数中创建 UserVO 对象，把可以给用户看的属性从 User 对象里提取出来，塞到 UserVO 对象里。 （新） UserService 把 UserVO 返回给 UserController。 （不变）UserController 把 UserVO 塞到 CommonResult 里，返回给用户。注意，这里 UserService 考虑了各种错误情况，throw 对应的 Exception，然后 UserController 根据 Exception 的类型，返回用 CommonResult 封装的错误信息。可是，我们发现 UserService 和 UserController 里充满了 try...catch。写其它接口的时候，可能会发现，大部分的 try...catch 都是相同内容的重复。在 SpringBoot 里，我们可以使用全局异常处理来简化。全局异常处理我们可以创建一个类 GlobalExceptionHandler，打上 SpringBoot 的特定标签，让它处理整个程序任何地方的 Exception，像这样：@ControllerAdvicepublic class GlobalExceptionHandler { // @ExceptionHandler 告诉 SpringBoot，所有的没有 catch 的 `NotFoundException` 全部送给这个函数处理 // @RespondBody 告诉 SpringBoot 把返回的对象变成 JSON（我们的 @RestController 标签其实就包含了 @ResponseBody) @ExceptionHandler(value=NotFoundException.class) @ResponseBody public CommonResult&amp;lt;String&amp;gt; notFoundExceptionHandler(NotFoundException e) { return CommonResult.failed(e.getMessage()); } // 处理剩下的所有 Exception @ExceptionHandler(value = Exception.class) @ResponseBody public CommonResult&amp;lt;String&amp;gt; exceptionHandler(Exception e) { e.printStackTrace(); return CommonResult.failed(e.getMessage()); }}然后，Service 和 Controller 就变得简单了，不需要处理 Exception，只需要在函数头部声明 throws Exception 就行。先看 UserController 中的请求处理：@GetMapping(&quot;/users/{id}&quot;)public CommonResult&amp;lt;UserVO&amp;gt; getUser(@PathVariable BigInteger id) throws Exception { User user = userService.getUserById(id); UserVO userVO = UserService.UserToUserVO(user); return CommonResult.success(userVO);然后是 ProductService 里的对应函数：public User getUserById(BigInteger id) { User user = userMapper.findById(id); if (user == null) { throw new NotFoundException(&quot;User not found&quot;); } return user;}于是，异常处理的篇幅被大大缩减了。优雅。接口文档前端开发人员需要使用接口从后端调取数据。为了节省沟通成本，后端开发人员需要把接口以文档的形式详细列出，包括请求的 url、请求的参数、可能的返回值，以及其它可能需要的信息。我们当然可以用 word 手写这样一份文档，但是维护起来可能比较麻烦（而且用微信传来传去的非常不优雅）。推荐使用 Springfox 去做这件事。只要进行一些配置，就可以自动生成非常漂亮的接口文档。具体的使用方法，官方文档讲得非常详细了。但是暂时不建议通读，因为不需要每个人全盘掌握。可以在开发团队里面找个人专门负责这一块，然后阅读文档，进行配置。如果只是想使用基础功能的话，只需要在 pom.xml 里面加入这个依赖：&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;io.springfox&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;springfox-boot-starter&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;3.0.0&amp;lt;/version&amp;gt;&amp;lt;/dependency&amp;gt;然后在应用程序入口 class （就是那个有个 main 函数，里面有一句 SpringApplication.run() 的) 上方加入 @EnableSwagger2 即可，做完之后，看起来是这样：@SpringBootApplication@EnableSwagger2public class DemoApplication { public static void main(String[] args) { SpringApplication.run(DemoApplication.class, args); }}之后，你可以从 base_url/swagger-ui/index.html 去访问你的接口文档。你也可以自己配置这个路径。注释及其它对于一些不是很明了的逻辑，我们要写注释，确保不看代码也能知道下面做的事情是什么。同时，推荐对每个 class 以及下面的每个 method 都按照 Javadoc 的规范去书写注释，这样就可以自动生成文档。具体教程参考这里，或者直接搜索 Javadoc。另外，我们放出阿里开发规范手册供大家参考。可以尽量去学习，然后制定自己认为最优秀的开发规范。" }, { "title": "软件工程流程和心得", "url": "/posts/se-and-tools/", "categories": "Software Development, Software Engineering", "tags": "notes, experience, tutorials, software engineering, chinese", "date": "2021-04-14 04:00:00 -0400", "snippet": "I wrote this for the m5-201 course, which aims at preparing new programmers for real full-stack development and tech team leader roles.引言其实，一个软件从无到有的过程中，书写代码只占了一小部分而已。与其它工程项目（比如造房子、发火箭、修铁路）一样，开发一个软件，需要使用科学的工程方法。否则，代码写得再好，也必然面临失败。一般，面向技术人员的软件工程课程会采取乙方的视角。具体的场景是，你的客户（甲方）想要你帮忙开发一个软件，你要做的第一步是与之交谈，明确甲方的需求；之后，你只负责按照甲方的需求去把东西做出来，而不需要去考虑做的东西是不是有用，能为甲方带来多少收益。但是，我们这次会把视角放宽一些，考察整个产品从无到有的流程，并且介绍其中可能会用到的工具。注意，并没有一个所谓的最好的流程，我们需要根据团队和项目的实际情况进行微调。产品从无到有的流程准备工作痛点/商机的分析一个项目的想法一定不是凭空产生的。可能你在生活中遇到了不方便，或者认为某些问题有更好的解决办法，所以才产生了开发一个产品的想法。这就是痛点，或者商机。但是，你自认为的痛点，不一定就是准确的。所以，要进行详尽的考察。我们可以通过进行市场调研、用户访谈等，验证我们的洞察，从而精准定义我们的产品要解决的问题。我们会先成立一个小组去做这些事情，通过 Slack 或者 钉钉 互相沟通、发送通知、管理团队事务。最终，我们必须十分确定，我们定义出来的问题是真实存在的，而且用户有解决问题的需求。解决方案/可行性分析在前一步，我们已经将问题定义好。在这一步，我们开始定义解决方案。比如，我们通过上一步的工作，确认了在校生存在难以获得申研相关信息的问题，我们打算解决它。我们可以这样做：为每位同学匹配一位申研成功的优秀学长或学姐，当作申研导师，一对一传授经验。但是，学长学姐可能很忙，并不能提供太多帮助，所以多半不可行。我们可以考虑，用人工智能代替真人进行服务，但是这对算法有极高的要求，技术上多半不可行。或者，我们可以搭一个平台，让申请成功的学长学姐把经验分享在上面。这在各方面似乎都是比较可行的方案。于是，我们确定了解决方案。这才进入到软件工程的领域。也是在这里，一个项目才正式确立并开始进行。最初的小组会转变成一个正式的项目组，更多人会加入之前创建的 Slack 或 钉钉小组。从这里开始，我们就要使用 Trello 或者 Jira 进行项目管理了。具体的做法，我们会在 任务分配和进度把控 板块介绍。需求分析上面两个步骤，通常不是纯技术人员主导的（也许是市场或运营部门）。但是，从这里开始，技术人员就开始介入了。在这一步，技术人员要与其它部门的人紧密合作，将解决方案细化。上一步的解决方案是，我们要做一个申研经验分享的平台。到了这一步，我们要把它细化到以下程度： 我们的平台需要运行在 Web 和微信小程序端。 我们的平台要让用户登录后使用 用户需要发布申研数据 用户需要浏览其它人发布的申研数据 用户可以在申研数据下自由讨论 用户可以对申研数据进行收藏、点赞、举报、分享到朋友圈。 …这一步，各位熟悉的 UML 图就可以排上用场。大家可以使用 Visual Paradigm 或者 亿图 之类的绘图软件作图，帮助团队梳理项目的脉络。非常重要的一点是，我们要评估手上的资源（包括时间、人力、资金等等），将所有的需求分出优先级，必要时进行舍弃。技术选型当确认了软件需求之后，我们要选择，用什么软件/框架去开发。比如，是 Web 端和微信小程序分开做呢，还是直接用 uni-app 写，然后多端编译？我们的后台是用 SpringBoot，Django 还是 node.js？如果用 node.js，我们是用原生 node.js，还是用 express？数据库是选择 MySQL 还是 MongoDB？是使用自建服务器还是云服务器？我们要根据项目和团队的实际情况，进行讨论，分析利弊，谨慎地作出选择。开发经历了这么多准备工作之后，这才到了写代码的部分。我们把项目切碎，分发给每个开发人员，在 Trello 和 Jira 上设置好时间线，通过 GitHub 管理代码，并尽量多地让这些软件之间联动（比如，Jira 可以通过 commit message 追踪 GitHub 的 commit，非常好用）。这个过程设计到一些代码规范，比如注释、文档、测试等等，我们之后会接触到。推广产品开发到一定程度（具体什么程度要看团队，存在那种还没开始开发就狂吹产品的团队），运营部门就会开始收集素材，包括文案、图片、视频等，然后制作推文、海报等推广用的东西。完成之后，市场部门就会拿着这些内容到处进行精神污染（i.e. 宣传），恨不得大家睁眼闭眼全是这些东西。上线假定我们开发和测试都没啥问题，我们的产品就可以部署、上线了。不出意外的话，用户会有很多反馈，比如新功能的需求和 bug 报告。技术人员需要一直维护，包括密切监视服务器状况、更新版本等等。当然，运营和市场的人会继续宣传；在必要的时候，法务、公关、财务也需要介入。任务分配和进度把控这是涉及项目管理的内容。和开发一样，项目管理也是需要专门去学习的。虽然它的入门门槛不是特别高，但要做好非常困难。我们并非专业，只能根据经验，给出一些建议。以下内容仅代表个人看法。任务分配和进度把控项目管理的核心之一。在项目的最终目标明确之后，我们要把它拆解成一个一个的小任务，设立好时间线。一个很好用的方法是，采用倒推的办法。比如，我们的平台八月份要上线，那么我们得七月份左右完成开发和推广内容制作，五月份要开始开发，四月中旬要把需求定好。然后，每个节点，又可以分成更小的任务，直到不能再分。就开发任务来说，通常一个页面的制作，就可以认为是不能再分的最小的任务了。任务划分好之后，我们要把任务分配到每个人身上。我们的建议是，每个任务，要有且仅有一个负责人，和明确的截止日期。项目经理和部门负责人，每过一定时间，就去观察一下进度，而不是放手不管，在截止日期当天才去问，任务完成了没有。Trello 和 Jira 是很好用的工具，可以很方便地把以上的 guidelines 落实下来。" }, { "title": "Recommendation System with Perfect Privacy - ONNX Runtime Web", "url": "/posts/onnx-runtime-web/", "categories": "Software Development, Machine Learning", "tags": "notes, experience, tutorials, software engineering, machine learning", "date": "2021-04-04 22:17:00 -0400", "snippet": "Recommendation System with Perfect Privacy - ONNX Runtime WebThe source code of the demo project is available here.PreludeSometime ago, a friend of mine drove me to a party with his new car. During the ride, we discussed why he bought the car, how the automobile market was, etc. The next day, when I logged into social media, I was flooded with car advertisements. I was again impressed by the development of the eavesdropping network. I’m pretty sure we all have experienced this to some degree. Privacy violation has been a problem that is so serious and omniscient that most people would just accept it as if they are doomed, or act helplessly against the monopoly of big tech companies. From my point of view, the status quo can result from the companies’ deliberate ignorance of user’s privacy in exchange for profit, or the failure to implement the technology that can protect users’ privacy while still being able to optimize for users’ personal experience. With the assumption that the second one is true, we are going to explore some technicalities of making privacy-preserving AI recommendations in this post.The Problem and the SolutionFor the rest of the post, let’s use the movie streaming scenario as a concrete example. Suppose there is a company that provides movie streaming service (similar to Netflix). To better personalize users’ experience, they would like to implement a system that recommends movies to users on their homepage. To achieve this, they have to collect data from users. However, users might be very worried about this part: can the company guarantee that the data they collect is only used for making movie recommendations? Could it be the case that after watching a movie with a lot of driving scenes, you suddenly start getting advertisements on their social media accounts? No one knows. Once your data is handed over to the company, you simply lose control, despite all the fancy promises they could make. If you were the CTO of the company, and given that you did want to protect users’ privacy, how could you implement the system to eliminate users’ worries? You have to run your model with the user’s data no matter what. Well, the answer is simple: instead of having users handing in their data to you, you hand in your model to the users. In our case, you can have users run your recommendation model on their browser with the data that they have locally. This is easily done with ONNX.ONNX and ONNX Web RuntimeONNX stands for Open Neural Network Exchange. A previous post has covered what ONNX is, its strengths and weaknesses, with an example usage. To summarize, ONNX is a platform agnostic format for saving, loading and serving a model. It allows you to, let’s say, train a model with PyTorch, save it in ONNX format, then load and use it in Tensorflow, Keras, C++, Javascript, or any languages and frameworks that has ONNX interface. If we want to run an ONNX model on users’ browsers, we could use ONNX Web Runtime. It provides a set of Javascript APIs that allows you to easily load a model and use it to make predictions. We will demonstrate how it can be used within a demo project.Develop a ModelYou may develop a model with your favorite language and framework. Be it PyTorch or Tensorflow, you are very likely to find ONNX support for that. In our demo project, we will be using scikit-learn and Python. We will create a simple linear regression model. Given a user and a movie, we will use this model to predict the rating the user would give to the movie. In this way, we can recommend movies that we think users will give the highest ratings to.A simple model training pipeline is implemented in models/get_regression_onnx_model.py. The pipeline will initialize a model, load a fake training dataset, train the model, then save the model weight in ONNX format. You can run the pipeline with.cd modelspython get_regression_onnx_model.pyWhen it’s done, you will see a model weight file in./models/linear_reg_recommender.onnx. The model will take 16 input features and predict a rating as a float number. Now that this part is ready, let’s try serving it to the users from their browsers. For this, we will set up a fake website which calls the model to make predictions.Build the WebsiteWe will create a react frontend project with create-react-app as follows:npx create-react-app onnx-recommender --template typescriptThen, install ONNX Web Runtime dependencies:npm install --save onnxruntime-web ndarrayTo make development easier, we also install a popular UI library antdnpm install --save antdWe will create a fake Login which handles user login logic (any password will be accepted) and a Recommender component that predicts the current user’s rating given a movie. The directory structure looks likesrc└───Components └────Login └───index.tsx └────Recommender └───index.tsxIt’s worth mentioning that, in Recommender, we use the following variables to mimic the data needed to make the prediction. In a real production scenario, localUserFeatureStore will the (encrypted) data of the users that have logged in from the device. It will be stored on the device and will never be given to the company. This ensures perfect safety of user’s private information. On the other hand, remoteMovieFeatureStore is stored in the company’s database, and can be fetched by the user at any time.const localUserFeatureStore: { [key: string]: UserFeature } = { &quot;guest&quot;: { age: 35, gender: [0.3333333, 0.3333333, 0.3333333], occupation: [0.25, 0.25, 0.25, 0.25], }, &quot;paulcccccch&quot;: { age: 24, gender: [0.9, 0.05, 0.05], occupation: [0.2, 0.5, 0.3, 0.4], }, &quot;nobita&quot;: { age: 10, gender: [0.5, 0.25, 0.25], occupation: [0.1, 0.2, 0.7, 0.3], }}const remoteMovieFeatureStore: { [key: string]: MovieFeature } = { &quot;Movie X&quot;: { genre: [0.12, 0.23, 0.34, 0.45], actors: [0.45, 0.34, 0.23, 0.12] }}We can follow this document or this example to prepare the input and retrieve the model’s inference result. After you login successfully, you will be able to see a rating as below:In real-world applications, the logic could be much more complicated than this. What we have done so far serves as a minimal workable component that can be extended to fit in different applications.DiscussionAlthough serving models at the frontend allows companies to create a recommendation system that perfectly protects user’s privacy, it has quite a few drawbacks compared to traditional cloud-centric recommendation: Not all models support ONNX conversion out-of-box. For example, only the listed models of scikit-learn are supported (see here). If there is no ONNX support out there, you may have to create your own serializer for your model, which can be time consuming. Models are now static files that can be cached at multiple places. When you try to update the model, you will have to invalidate the cache, which adds additional complexity to your pipeline. Without users sending data to the server, it will be more difficult for the company to continuously improve their model. Users will have to download the models from time to time when visiting the website, which can result in a lot of network traffic and disk usage.However, if a company really wants to protect user’s privacy, these issues are by no means unsolvable. For example, the models can be designed in a way that only a small portion of the weights need to be updated frequently. Also, the company could let users send back model weight updates, which allows the company to keep improving their model with users data while preserving users’ privacy.References A website built with React and legacy ONNX.js Official ONNX Runtime Web demo ONNX Model ZOO Converting scikit-learn model to ONNX ONNX Web Runtime doc" }, { "title": "The Void", "url": "/posts/void-x/", "categories": "Writing", "tags": "creative, writing, personal, chinese", "date": "2020-03-01 20:00:00 -0500", "snippet": "一些解释希望讲述一个关于宇宙和生命起源的爱情故事，用来致敬卡尔维诺的《宇宙奇趣全集》。假想了一个从虚无 (the void) 之中诞生的主体X，以及一个闯入虚无，在世界上创造出物质、给X带去烦恼的主体S。X因为S的出现，第一次感受到了主体之外的客观事实的存在，第一次参与了与世界的“互动”，但是忍受不了存在“意义”的世界，最终选择退回虚无。X终究还是在世界上留下了痕迹——他将自己的情感书写在了生命的DNA中，永远地在S创造的世界中传承下去。原前言两年前开的一个坑，写了一大半，然后就放那了…花费（浪费）了一个周末把它肝完…明天pre还没准备好（希望老师继续罢工），数据跑不出来，论文毫无头绪，还要担心美签和疫情（昨天英国确诊涨了50%）。看来还是不够忧虑（不。话说，当时好像是想致敬一下卡尔维诺来着（《宇宙奇趣全集》么…）把故事讲清楚还是太难了。对我来说。先这样吧，有空（never）再雕琢。哦，有错别字或者什么建议啥的纠一下呗（如果有耐心读完的话XD）就这样。2020.3.1正文A 不知道从什么时候开始，任何一点刺激都会引发我强烈的自我否定，会使我想起一切我做错的、错过的以及渴望却不可及的的事情，然后止不住地掉眼泪。真是折磨。如果可以的话，我想立刻结束一切；然而我不能。所以我只能安慰自己：我的存在本身就是酷刑，一切都是为了赎罪。 是的，我终于知道，存在是一种罪，爱也是一种罪。我要为我的后知后觉付出代价。 —— X的日记X感觉近来格外苦恼。哦，事实上，可以说，他从来就没有不苦恼过，只是在没有“意识”以前，苦恼是什么，谁在苦恼，为什么苦恼都是无从下手的问题。他觉得，他已经太久没有见到S了。他想，也许S已经意识到了他怪异的存在，于是想方设法地躲避；或者，S已经永远离开，再也不会出现了。他对这两种想法都喜忧参半。如果说，时间是一卷徐徐展开的素色卷轴，那么S就是其上间或出现的笔画，没有人——如果那个年代有人的话——知道下一笔会出现在什么地方，也没办法预计那是刚劲短促的一点，或是舒展绵长的一横。这便是S，她存在的“一瞬”时短时长，难以捉摸。她会毫无征兆地从某处降临，偷偷剪下一块黑暗来，编成薄纱，披在身上，或将它扯成片，撒手任其散落；被剪开的地方便会有光源源不断地漏进来，有红的，有黄的，还有蓝紫色的。而S呢，她只顾着在光与影的华尔兹里舞蹈，舞向那深不见底的黑暗，随后变戏法一般消失不见。有时候，她也是会将黑暗归还的，只是那自制的胶水并不总是能把那个漏光的小洞填成原来的样子。上次见S是什么时候呢？X努力思索着——没有参照，想说清楚时间可不容易呀。有那么一瞬，X新鲜湿润的记忆告诉他，S才走一小会儿呢。也许真就是在刚才吧，她踮着步子，很轻盈地起伏、起伏，身后轻纱翻卷，拂起莹莹的尘埃，留下一条幻影落成的长径，通向她消失的地方。X在一旁偷偷欣赏，长舒着哀惜般的赞叹。真是轻柔而潇洒的舞步。X感叹。他觉得，时间和空间开始朝S跌落过去，自己变得越发模糊了。B S又走了。这次她呆的时间格外地久呢。 临走的时候，她从袖中取出黑暗，糊在一处漏光的地方，轻轻地捋了几遍，于是挑了块平坦的地方坐下，不一会儿便眼角低垂，神色凝重起来。 我仍在远处，悄悄地看她。 世界一下子变得寂静，这从来都是与S的存在相矛盾的。 我又想起了最初没有S的世界：那是无穷无尽的黑暗，此处与彼处、过去和未来没有分别，一切都是虚无自我复制的产物。是她把时间断作分明的小节，也是她，把空间割裂成“远处”和我望而不及的“她的身旁”。 她还会给我带来什么吗？ —— X的日记X从回忆中惊醒过来，心绪更失落了几分。眼前的世界，到处都是S留下的痕迹：遍地都是尘埃，有的散漫地飘着，扩展成怪异的图案；有的静静凝聚，结成一个个星球，悠悠地拨弄着其它尘埃；各色的光毫无章法地四处奔走，碰撞、扭曲、缠绕、堆积，一刻不停。然而他却见不到S了。X想，也许S的行踪隐匿在了这恼人的喧嚣中，也许S踏上了寻找更肥沃的黑暗的旅途，又或许，她注意到并决定躲避自己。于是，他又开始懊丧，不知所措。S的旗帜死死地插在了这个世界上，这使得X对过去的记忆日渐模糊。他开始对虚无感到陌生，并且逐渐习惯了空间与时间。他看向光线达不到的角落，试图找到一些参照，帮助自己回忆世界最初的样子。但是，他仍很清楚，光在空间中的缺失与他想要回忆起的虚无毫无共通之处。X很想接受这个世界，就这样溶解在这缤纷的嘈杂中，可没有S的世界让他感到恐惧：他不知道该做些什么。不，X的处境显然比不知道“该做什么”复杂得多，因为要回答“该做什么”，只需要回答“什么”，而生于虚无的X，“做”本身就是一件不可想象的事情。他是彻头彻尾的慌乱。他不知道什么是问题，更不用说什么是答案。然而，S却可以抚平这一切。S出现的时候，他能感到时间和空间都被她吸引过去。她美好的身姿，让世界上的其它一切都显得无关痛痒。在S的舞步中，世界变得简单纯粹，这让X感觉有如回到空无一物的虚无一样。可惜，S离开了。也许是永远。X觉得，S就像是一个蛮横的入侵者，夺走了他的宁静，然后扬长而去。他想，S若是永远离开，何不把她带来的东西也带走呢。想到这，他感到一股暗流在涌动，不自觉地抓起一个星球，随手甩了出去。紧接着，令他没想到的是，星球飞去的方向上突然迸发出猩红的光；几乎在同时，像是一滴颜料落到纯净的宇宙之水里，火星向四面八方迸发出来，随后慢慢暗淡下去。等到平静下来，刚才那些看起来就像是没发生过，或者被抹去了一般，找不到痕迹了。X不是没看过这样的“烟花”。相反，对这种时有发生的事情，他早已熟习。重要的是，刚刚那一掷，是他第一次与世界的互动，他由此发现了一种新的可能性。这会儿，他一面因为兴奋而不知所措，迫切地想要挖掘出这种“互动”的内涵，一面又隐隐地感到不安。不过，他似乎很乐在其中。到底意味着什么呢。X思索着。不过他不用着急的，毕竟他有的是时间。C 我觉得，最近近乎瘾性的行为，与其归因于新鲜感，不如说，这是一种出于自卫的反击。 上次的爆炸之后，我意识到，世界并不完全是S的。于是我戳戳这里，碰碰那里，把尘埃搅在一起，把星球打碎…S已经把这里弄得很乱了，但是我要把它弄得更乱一些，以此昭示自己至少与S有同等地位。这在我看来算是对她无礼入侵的积极回应吧。 做这件事的时候，充盈的感觉是从来没有过的。 加油啊，X！ —— X的日记尘埃在光的华尔兹里舞步回环，闪耀的金属如同花瓣般散落，与尘埃嵌在一起，结成坚硬的核。X的周围越来越丰富了。X开始研究起S留下的东西。关于她的一切似乎都很有趣。她散落的星火在围着那块缺失的黑暗旋转，看起来就像一个圆盘。有好几次，他瞥见远处跳动的物体，以为是S来了，只可惜视线被太多东西遮蔽，看不真切。是不是S已经出现好多次，只是自己没有注意到呢。X想。他已经太久没有见到S了，或许他已经忘记S的身姿与眼眸了。S到底是什么样子的呢？X努力重现那些画面——她有黑暗做纱衣，有光做随从；她的舞步轻快，身姿潇洒。X回忆着，不觉间随意摆弄着的星球被捏出了凹凸不平的形状。呀，他差点以为，S又来改变他的世界了。X轻柔地抚摸，星球不安起来，有如烧沸的果酱，不时闪烁着鲜红的光。他想把星球雕成S的形状。可是这要花多久呢？X一遍摩擦、揉捏，一边在心里预估着时间。也许是S头两次出现之间的间隔吧，他想。大概是真的过了这么长时间，X一撒手，雕塑便开始平静而缓慢地向黑暗驶去，坠向看不到尽头的时间和空间。在雕塑即将被星空淹没的时候，X突然将它拽了回来；接着，他挑选了一颗明亮的星，把雕塑挂在它周围。于是，雕塑围着那颗星逐渐迈开舞步，回环地向远方滑去。黑暗在它身后凹陷下去。也许这就是S的样子吧。X想。如此漠然地离去，的确是像极了S呢。X打算再做几个雕塑。慢慢地，机械的动作使得X感到荒谬。他一面重复着动作，一面却用思绪飘荡到别处。他想到，S的入侵不仅改变了世界，还改变了他自己：S把自己变成了一个可以和世界互动的什么物体。突然，X意识到一种可能性：也许，自己就是S创造的物体，自己就是光和星辰，或者什么类似的东西。是这样吗？X感到害怕。自己曾经是虚无世界的主人，现在却被囚禁在时间与空间中，单调地与世界互动着。X不愿意接受这个可能性。他不想再与世界有更多互动了。他决定，要把世界改回去，彻底把关于S的一切都赶走。他要回到虚无的安乐乡。D 我真是受够了那些乱七八糟的东西。我可以移动、击碎甚至点燃它们，但是不论我做什么，它们总是那么多，丝毫也没有减少！ 不过最近我发现，缺失的黑暗其实是一些“坑”，扔进去的东西会消失不见。虽然我能感受到它们还在那里，但是好歹它们不再乱跑。如果能把所有东西都扔进去，那世界该多清净！ 看起来要忙活好一阵了。至于要怎么把这些坑给消除掉，之后再说吧。 —— X的日记X颓丧地环视，光与星辰仍各自奔忙，而他的目光里尽是无奈。很长一段时间里，他一直欢欣地追随回归虚无的脚步，但是现在，他又开始怀疑起来。S的影响真的能消除吗？只要时间和空间还在，他就不能不想到S。甚至，即便一切都消失了，世界回到S从未出现过的时候那样，他也是忘不了S的，因为是S让他意识到了记忆的存在，记忆的每一个片段，光、星辰、黑暗甚至虚无，都与S有所关联；他也无法停止对S的渴望：他想永远看着她，让时间和空间就这样消解，如同回到一无所有的虚无。消除这些可比消除物体难多了！X觉察到了自己的无力，只是一直不愿意承认。他显然陷入了挣扎，不知道自己该做什么。是继续填坑，还是放弃。他意识到自己必须作出选择，而选择需要有原因，或者说，意义。他想找出填坑的意义，进而想到了回归虚无的意义，于是思考虚无和这S带来的世界之间的差别；最后，他意识到，是自己的渴望导致了一切的差别。到头来，都是因为自己。自己的存在是一切的源头。有必要存在吗？X想。他开始困惑于自己存在的意义，感到了从未有过的苦恼。在一个从来不需要考虑“意义”的世界，一切都安详而美好；意义出现之后，评估性的思考随之而来。此后，再也没有什么可以脱离意义正当地存在了。除非不存在，否则X必须找出存在的意义。于是，他尝试消除自己的存在。他想，如果消除了自己，他就看不到光和星辰，感知不到时间和空间，并且无法回忆S的一切，听起来就像一条回到虚无的捷径。可是，他完全无从下手。如果他真的是一个物体，那么他最多可以把自己打散，填到坑里去，但是这不能消除他的存在；如果他不是一个物体呢？这让他更加没有头绪。看来，X似乎得接受自己的存在。他现在必须找到一个意义，或者说，一个能说服自己的辩护词，好理直气壮地寄居在这个世界上。于是，他决定期盼再见到S，以等待为由继续存在。可是，如果S真的再也不来了，那他还有必要这样较劲吗？不，不会的。他想。S一定会再出现的，只要他一直等待。E 我很困惑。 我究竟是什么？我是黑暗吗？黑暗可没法拨弄尘埃。我是星辰吗？其它星辰也会和我一样思念S，思念虚无吗？还是说，我就是虚无？可是当虚无触碰到尘埃，虚无不就消失了吗？为什么我还存在呢？不知道。不知道。 啊，我太想念最开始那纯净的世界了！这个世界会一直这样下去吗？这时间和空间什么时候会停止？我要永远忍受痛苦吗？S终究是不会再来了吧！会吗？不会？ 唉！痛苦！痛苦！ —— X的日记对于能再见到S这一信念，X决定不再去质疑。准确地说，他不敢再去质疑，因为每当他思考永远见不到S的可能性，那“永远”带来的绝望便会让他感到痛苦，无法忍受的痛苦。相反，X开始考虑，当S再出现的时候，他该怎样劝说她留下，永远留在这时间与空间中。他该如何表述呢？他怎么才能让S理解他的渴望呢？X想创造一些东西来表达。于是他思考，渴望是什么形状的呢？他随手抓了一个星球，捏出了一些棱角，随后又把它撕成两半，反转过来拼在一起。不像。X想。他决定重新尝试，于是他又抓来了一个。这次，他在圆润的表面上刺出了好多孔，把发着金灿灿的光的东西从孔里灌进去，那光芒很快就褪成了暗红，染遍了整个星球。这看起来像他的渴望吗？似乎也不太像。他学着S把黑暗撕下，光便漏进来。然而他不小心用力过猛，撕出了一片刺眼的亮光，似乎点亮了整个世界。好在，这爆发似的亮光很快就黯淡下去，只留下缺失的黑暗。他又很小心地撕下一块。这一次，光很柔和，很安静。他终于知道，这便是那些明亮的星星的由来。它燃烧得沉闷而持久，像极了他的渴望。可是，它也逐渐消散、黯淡了，最后只留下一个坚硬冰冷的小球。他让岩石从星球表面高高隆起，然而那岩石却像液体一样瘫软下来，回到星球表面；他让尘埃排列成波浪的形状，可是它们总是不安分地扭作一团；更多时候，他还没来得及欣赏自己的创作，远处飞来的什么东西就把他的作品打得粉碎。X很是气恼。似乎不论做什么，他都不能在这个世界上留下什么有意义的东西。他什么也不能表达。他不解，为什么S可以给世界带来这么大的改变，而自己却什么也做不了。他想，也许是S禁止了他改变她创造的世界。也许他不过是那些光与星辰，本不该有表达的能力。他彻底绝望了。F S啊，这一切是为什么！ 为什么你要囚禁我，为什么你要囚禁这些光与星辰！ 我渴望你的美，渴望没有时间与空间的虚无，我该如何让你理解！ 啊！那溶解时间与空间的美！为什么，哪怕只是轻轻的一瞥，也能让我迷醉许久？ 你还会回来吗？即便你回来，你也还是会走的吧？ 你会注意到我吗？你不会的吧！ 你是一切。而我呢？我只是一片黑暗，或者一棱光，一块岩石，一个影像，一缕意识。或者，我什么都不是。 S，我觉得自己已经没有办法继续存在了。我想离开。 我要离开。我会离开。 我一定可以离开的。 —— X的日记X的思绪慌不则路地逃窜着，似乎在被痛苦追赶，一刻也不能停歇。他幻想前方是一片虚无，他一头扎入其中，世界便只剩下了他自己；不，连他自己也不剩下了：没有物体，没有回忆，没有意识，纯粹而安详。他幻想与S在群星间共舞，世界便只剩下了S。一切仍存在，只是没有了内涵；S的美是唯一的意义。他幻想一个没有永远的世界。那里有光与星辰，他可以尽情地与世界互动，然后消逝，连同他的痕迹，连同所有痛苦与渴望。他幻想一个有奇迹的世界。在那里，渴望会变成现实。他无需挣扎着以行动徒劳地自救，他可以大胆地去相信、去期盼，用奇迹为自己的存在做辩护。他幻想一个没有意义的世界，一个没有差别的世界。这样的世界…这样的世界会存在吗？他猛地质疑了一下，仿佛痛苦还是追上了他，无情地挥出了带刺的长鞭。X意识到，只有遁入自己的思绪，才能摆脱这个世界的痛苦。他又一次与痛苦开始了赛跑。他看到星辰渐渐明亮起来，散落成尘埃；他看到光在折反，回到被撕开的黑暗中去。他看到一切都在渐渐黯淡，世界就要褪回虚无。他看到S披着精致的薄纱，伴着明媚的光和星辰，从远方向他伸出套着黑暗的手臂，请他共舞。他犹豫地靠近，却在就要触及到S的那一瞬，狠心地退了回去。S灿烂地笑了。她转过身，蹦蹦跳跳地离开。世界安静得令X感到不习惯。他的眼前便是纯净的虚无，他渴望已久的故乡。身后，光与星辰朦朦胧胧地眨着睡眼，即将苏醒，S远去的背影在它们中间若有若无。他知道自己就要离开了，那让人绝望的永恒终于就要终结。最后一次，他忘情地陶醉在S的舞蹈中，忘情于光与星辰的前奏曲。待到他动身离开时，他的泪水已经湿遍了一方星河。G这便是X的故事。他脱离了自己的躯壳，让意识从思绪里逃回了虚无。可以说，他还是以躯壳的方式存在，不过，他不再渴望，不再追问意义了。与那些光与星辰一样，他的躯壳在S创造的世界里奔忙，冰冷、麻木。世界就这样运行、运行，直到永远，直到那也许不会到达的时间和空间的终点。这就是全部的故事了吗？不，还有很多。X离开了，但他却留下了他的泪水，那凝结了他的渴望的泪水。泪水浸润着X最精细的作品——一篇用一串符号表达的诗行，在被赐福的星球上扎根。从那以后，生命在这些星球上此起彼伏，从蠕动的虫，到飞翔的鸟，再到能在世界上自由穿梭的更高等的生灵，它们都承载着这首永恒的诗，用自己的存在歌颂着虚无，歌颂着美，歌颂着X的痛苦与绝望，还有他的渴望与思念。它们也在诉说着自己的故事，它们的爱与恨，泪与笑，挣扎与轻蔑，希望与妥协。纵使星光消逝，生命依然会找到它们的方式，一代一代地把这首诗传颂下去。它们会像X一样追问意义吗？它们会像X一样感到无法忍受的痛苦吗？不必为它们担心。它们不过是些朝生暮死的灵魂，还没来得及追问意义和感受痛苦，就已经逝去。它们从一开始就知道自己很快就会消逝的结局，便可以尽情享受自己的存在，而无需为永恒烦恼。它们会繁衍，四处奔波，把那寄托渴望的诗篇带向世界的各个角落。世界继续运转，时间一刻不停。有朝一日S再次降临，看着这熙熙攘攘世界，一定会为X的深情动容的吧。不过，她什么时候来呢？没有关系，虽然它们还年轻，但它们不会有多少时间可以用来等待的。2018.2.24 - 2020.3.1" }, { "title": "Intuitions of Lagrange Methods Behind SVMs", "url": "/posts/Lagrange-Methods/", "categories": "Study Notes, Maths", "tags": "notes, maths, optimization, tutorials", "date": "2019-12-14 21:12:00 -0500", "snippet": "Lagrange MultipliersSet upConsider the problem of minimizing a function $f(x)$ given $n$ constrants $h_1, h_2, …, h_n$, i.e. find a $x = {x_1, x_2, …, x_k }$ such that\\[\\begin{aligned}&amp;amp; x = \\min_{\\hat x} f(\\hat x) \\\\s.t. &amp;amp; \\ h_i(x) = 0, i = 1, 2, ..., n\\end{aligned}\\]IntuitionWe can try to imagine it in two dimensions, i.e. $k = 2$. We think of $f(x)$ as a basin and $h_i(x) = 1, 2, …$ as contours. Imagine that you are trapped in an basin. There is toxic gas everywhere above you, and the higher you get, the sooner you will die. Therefore, in order to live longer, you have to descent as much as possible. This is the task of minimizing $f(x)$. On the other hand, you cannot just simply rush downwards. There is also monsters everywhere. You have to stay in the path lit by fire to protect yourself from being attacked. This is the task of satisfying the constraint $h_i(x) = 0$.There is no light at all at the very bottom (level -500) of the basin, So, you start walking upwards unwillingly (you know are inhaling more and more toxic as you go upwards, but you have to do it so as to avoid monsters). When you are at level -400, you look around and try to find if there is any light at this level (i.e. does the path lit by light passes through level -400?). Unfortunatly, you don’t see any. You keep going up. At level -300, you still don’t see any, yet you know you are getting close. Not surprisingly, at level -233, you found that a tiny bit of the path just barely touches level -233. You finally reach the light, stay there and wait for rescue. Level -233 is the best you can hope for: there is no light at level -234, and the air is more toxic at level -232.What is interesting is the word ‘barely touch’. Actually, no matter how funny the path of fire may look like, when you get to the optimal level, you will always find that the path barely touches your level without passing through. If it passes through level -233, that means you can also get light at level -232, so you are not at the optimal level.I hope this explains the follwing: at a minimum point of $f(x)$, the contour of $f(x)$ must be tangent to the contour of $h_i(x)$ (i.e. the path of fire barely touches the level).Equivalently, we can say that the gradient of these two functions has to be parellel, i.e. for each $i$\\[\\nabla f(x) = \\lambda_i \\nabla h_i(x)\\]The proof relies on something called Implicit Function Theorem. For now just hold the belief that the intuition is indeed correct.AlgorithmTo solve this kind of problems, we first construct a Lagrangian function.\\[L(x, \\lambda) = f(x) + \\sum_{i=1}^n \\lambda_i h_i(x)\\]The problem now is equivalent to\\[\\min_{x, \\lambda} L(x, \\lambda)\\]Then, we solve it with the following system of equations:\\[\\begin{cases} \\nabla_x L(x, \\lambda) = 0 \\\\ h_i(x) = 0 \\text{ for } i = 1, 2, ..., n \\end{cases}\\]or more explicitly\\[\\begin{cases} \\frac{\\partial L(x, \\lambda)}{\\partial x_1} = 0 \\\\ \\frac{\\partial L(x, \\lambda)}{\\partial x_2} = 0 \\\\ ... \\\\ \\frac{\\partial L(x, \\lambda)}{\\partial x_k} = 0 \\\\ h_1(x) = 0 \\\\ h_2(x) = 0 \\\\ ... \\\\ h_n(x) = 0 \\\\ \\end{cases}\\]Generalized Lagrange FunctionReferenceshttps://zhuanlan.zhihu.com/p/38163970https://www.cnblogs.com/ooon/p/5721119.htmlSet upConsider the a more complex problem of minimizing a function $f(x)$ given inequality constraints $h_i \\le 0$ instead of $h_i = 0$\\[\\begin{aligned}&amp;amp; x = \\min_{\\hat x} f(\\hat x) \\\\s.t. &amp;amp; \\ h_i(x) \\le 0, i = 1, 2, ..., n \\\\\\end{aligned}\\]IntuitionInstead of a curve in 2d space (or a ‘path of fire’), the constraint now becomes an area in 2d space (or an area covered by the ‘holy aura’).The problem looks similar as before except that we need to consider two different cases:Case 1The lowest point of the basin lies inside the area.In this case, the constraints becomes useless, since you are going to go to the lowest point any way. You can forget about the constraint, and the problem becomes $\\min_x f(x)$.Case 2The lowest point of the basin lies outside the area. In this case, we need to find the lowest point in the basin that is covered by the ‘holy aura’. Similar as the ‘path of fire’ case, we will still find that the optimal level ‘barely touches’ the boundary of the ‘holy aura’. In other words, we still have $f(x)$ tangent to $h_i(x)$. Yet, this time we need to add some more constraints. We require that the gradients of $g_i(x)$ and $f(x)$ point to the opposite direction, i.e.\\[\\begin{cases} -\\nabla f(x) = \\lambda \\nabla_x g(x) \\\\ \\lambda &amp;gt; 0\\end{cases}\\]Think of it this way: the ‘holy aura’ decreases the ‘power of darkness’. Outside the aura, the power of darkness is larger than 0, meaning monsters will thrive. Within the aura, the power of darkness is suppresses to negative, so the monsters cannot get in. At the edge of the aura, the power of darkness will be exactly 0. So, when you stand at the edge of the aura and look towards the bottom of the basin, you need to make sure that, as the level goes down, the power of darkness goes up. If the opposite is true (the power of darkness shrinks as you go down), you will be able to safely walk towards that direction and lower your position. This makes the point where you stood a sub-optimal point.Generalized Set UpConsider the a more complex problem of minimizing a function $f(x)$ given not only equality constraints $h_i = 0$, but also inequality constrants $g_j &amp;lt;= 0$:\\[\\begin{aligned}&amp;amp; x = \\min_{\\hat x} f(\\hat x) \\\\s.t. &amp;amp; \\ h_i(x) = 0, i = 1, 2, ..., n \\\\ &amp;amp; \\ g_j(x) \\le 0, j = 1, 2, ..., m \\\\\\end{aligned}\\]AlgorithmDefine the lagrangian function\\[L(x, \\lambda, \\mu) = f(x) + \\sum_{i=1}^{n} \\lambda_i h_i(x) + \\sum_{j=1}^{m} \\mu_j g_j(x)\\]Then, we try to solve the following (a.k.a. KKT conditions. Given convex function $f(x)$ (and with some other constraints), $x$ is the minimum if and only if KKT conditions hold):\\[\\begin{cases} \\nabla_x L(x, \\lambda) = 0 \\\\ h_i(x) = 0 \\text{ for } i = 1, 2, ..., n \\\\ g_j(x) \\le 0 \\text{ for } j = 1, 2, ..., m \\\\ \\mu_j \\ge 0 \\\\ \\mu_jg_j(x) = 0, j = 1,2, ..., m \\end{cases}\\]Where condition 1 finds the minimum of $f(x)$, condition 2 and 3 are initial constraints, condition 4 ensures the gradients of $h_i(x)$ and $g_j(x)$ to point to opposite directions (see the ‘holy aura’ analogy, case 2).Condition 5 follows the first case in our ‘holy aura’ analogy. When the minimum of $f(x)$ lies within the permissible area, i.e. $g_j(x) &amp;lt; 0$, we do not need to consider the constraints $g_j(x) \\le 0$ anymore. We let $\\mu_j = 0$, and $g_j(x)$ will automatically lose its power to constrain. When the minimum of $f(x)$ is on the edge of, or outside the permissible area, we have we are guaranteed to find the optima at $g(x) = 0$. In either case, we have $\\mu_jg(j) = 0$.DualityIn fact, even if we have the KKT conditions, it can be hard to find a solution. To solve for $x$, We can combine the conditions together to form an equivalent problem with a single equation, and simply throw away other constraints:\\[x = \\min_{\\hat x} \\max_{\\alpha, \\beta} L(x, \\alpha, \\beta) \\\\\\]Why can this problem be free of constraints? The idea is the following.Think of it as a game of two players against each other. Player 1 tries to pick an $x$ that minimizes $L(x, \\alpha, \\beta)$, while player 2 tries to pick an $(\\alpha,\\beta)$ pair that maximizes it.If player 1 picks an $x$ that does not satisfy the constraints (e.g. by making $g_k(x) = 0.2$), player 2 will take advantage of it by making $\\mu_k = +\\infty$. The resulting function value will be $+\\infty$, a crushing defeat for $x$. Therefore, player 1 has to pick $x$ wisely to satisfy the constraints.Interestingly, if $L(x, \\alpha, \\beta)$ is convex and KKT conditions hold, we can simply switch the order of ‘min’ and ‘max’, and the result is guaranteed to be the same:\\[\\begin{aligned}x &amp;amp;= \\min_{\\hat x} \\max_{\\alpha, \\beta} L(x, \\alpha, \\beta) \\\\&amp;amp;= \\max_{\\alpha, \\beta} \\min_{\\hat x} L(x, \\alpha, \\beta) \\\\\\end{aligned}\\]This is called the dual problem of the original problem.We can then solve the equation. We first try to find the solution to the inner minimization problem using\\[\\frac{\\partial L(x, \\alpha, \\beta) }{\\partial x} = 0\\]Then, we use some iterative algorithm to solve the outer maximization problem. Suppose the solution we got in the previous step was $\\psi(\\alpha, \\beta)$, we need to find\\[\\alpha^*, \\beta^* = \\arg \\max_{\\alpha, \\beta} \\psi(\\alpha, \\beta)\\]Finally, we substitute in the optimal $\\alpha^* $ and $\\beta^* $ and get our $x$ value:\\[x = \\psi(\\alpha^*, \\beta^*)\\]Referenceshttps://www.cnblogs.com/liaohuiqiang/p/7805954.htmlhttps://www.bilibili.com/video/BV1aE411o7qd?p=32" }, { "title": "SLM Chapter 7 Support Vector Machines", "url": "/posts/C7-SVMs/", "categories": "Study Notes, Statistical Learning Methods", "tags": "machine learning, notes, maths, tutorials, english", "date": "2019-12-08 21:12:00 -0500", "snippet": "SVM is essentially separating data with planes, such that the margin between two classes is the largest.TypesLinear SVM in linearly separable case: simply uses a hyperplane (with hard margin) to classify linearly separable data.Linear SVM: uses a hyperplane with soft margin to separate data. The data in this case is almost linearly separable.Non-linear SVM: use a mapping (usually non-linear) to transfer the data from the input space to a feature space.Distance MeasureFor a given data point $(x_i, y_i)$ and a classifying hyperplane defined by $(w, b)$, the functional margin between the point and the plane is\\[\\hat D_i = y_i(wx_i + b)\\]When $(x_i, y_i)$ is correctly classified, the (signed) geometric margin (signed euclidean distance) is\\[\\begin{aligned}D_i &amp;amp;= \\frac{\\hat D_i}{||w||} \\\\&amp;amp; = y_i(\\frac{w}{||w||}x_i + \\frac{b}{||w||})\\end{aligned}\\]Note that if there is misclassification, we have $D_i \\le 0$.Unlike functional margin, geometric margin does not change as you scale $w$ and $b$ up.Problem Setup: Hard MarginWe want to obtain a classifier that has a maximum margin between two classes. We define the margin of a perfect classifier (i.e. one that separates two classes perfectly with no misclassification, so that $D_i \\ge 0$ for all $i$) as\\[D_{w, b} = \\min_{i=1,...,N} D_i\\]Learning the SVM model can be viewed as the following optimization problem\\[\\begin{aligned}&amp;amp; \\max_{w, b} D_{w, b} \\\\s.t. \\ &amp;amp; y_i(\\frac{w}{||w||}x_i + \\frac{b}{||w||}) \\ge D_{w,b} \\\\\\end{aligned}\\]We plug in the functional distance of the model $\\hat D_{w,b}$ and get an equivalent problem\\[\\begin{aligned}&amp;amp; \\max_{w, b} \\frac{\\hat D_{w, b}}{||w||} \\\\s.t. \\ &amp;amp; y_i(wx_i + b) \\ge \\hat D_{w,b} \\\\\\end{aligned}\\]If we scale $w$ and $b$ carefully, we can make $\\hat D_{w, b} = 1$ without changing our perfect classifier (think about the equivalence of two lines $x + y + 1 = 0$ and $2x + 2y + 2 = 0$). In other words, we make the functional distance between our perfect classifer and the points closest to the decision boundary to be 1. All other points should have a functional margin greater than or equal to 1.Therefore, we get our final optimization problem as a Lagrangian optimization problem. Note the equivalence between minimizing $ \\frac{1}{ ||w|| } $ and maximizing $ \\frac{1}{2} ||w||^2 $.\\[\\begin{aligned}&amp;amp; \\min_{w, b} \\frac{1}{2}||w||^2 \\\\s.t. \\ &amp;amp; y_i(wx_i + b) - 1\\ge 0 \\\\\\end{aligned}\\]We can then write it as its dual problem (read more about Lagrangian optimization problems):\\[\\begin{aligned}&amp;amp; \\max_\\alpha \\min_{w, b} L(w, b, a) \\\\= &amp;amp; \\max_\\alpha \\min_{w, b} \\frac{1}{2}||w||^2 - \\sum_{i=1}^{N}\\alpha_i(y_i(wx_i + b) - 1) \\\\= &amp;amp; \\max_\\alpha \\min_{w, b} \\frac{1}{2}||w||^2 - \\sum_{i=1}^{N}\\alpha_iy_i(wx_i + b) + \\sum_{i=1}^{N}\\alpha_i\\end{aligned}\\]We first deal with the inner minimization problem by solving the following\\[\\begin{cases} \\nabla_wL(w, b, a) = 0 \\\\ \\nabla_bL(w, b, a) = 0 \\end{cases}\\]We get\\[\\begin{aligned} w^* &amp;amp;= \\sum_{i=1}^N \\alpha_i y_i x_i \\\\ 0 &amp;amp;= \\sum_{i=1}^N \\alpha_i y_i\\end{aligned}\\]For a sample right on the decision boundary $(x_j, y_j)$, we have $y_i(w^* x_j + b) - 1 = 0$. We solve for $b$ and get\\[b^* = y_j - \\sum_{i=1}^{N} \\alpha_i y_i x_i x_j\\]However, we don’t need to plug $b$ back. During the calculation, $b$ is eliminated by the fact that $\\sum_{i=1}^N \\alpha_i y_i = 0$Then we plug in the solution to the outer maximization problem and get our final expression that we need to optimize:\\[\\begin{aligned} \\min_{\\alpha} &amp;amp; \\frac{1}{2} \\sum_{i=1}^N \\sum_{j=1}^N \\alpha_i \\alpha_j y_i y_j x_i x_j - \\sum_{i=1}^N \\alpha_i \\\\ s.t. &amp;amp; \\ \\sum_{i=1}^N \\alpha_i y_i = 0 \\\\ \\ &amp;amp; \\alpha_i \\ge 0, \\ i = 1,2,..., N \\\\\\end{aligned}\\]Note that we took the negative away so the problem turned into minimization.We solve this problem, get our solution $ a^* $, calculate $ w^* $ and $ b^* $, and result in the final model\\[f(x) = \\text{sign}(w^*x + b^*)\\]Note that $b^* $ and $w^*$ are only determined by a few points lying on the boundary, for which $\\alpha$ values are not zero.Problem Set Up: Soft MarginPreviously, we require that for any $i = 1,2,…,N$, the following holds\\[y_i(w x_i + b) \\ge 1\\]When the data set is not linearly separable, this will become impossible to achieve. Thus, we introduce a slack variable $\\xi$ to allow some misclassification. Our new requirement becomes\\[y_i(w x_i + b) \\ge 1 - \\xi_i\\]and, with a new term as a punishment for misclassification, out target function becomes\\[\\frac{1}{2}||w||^2 + C\\sum_{i=1}^N \\xi_i\\]where $C$ is a parameter for punishment.The optimization problem is now\\[\\begin{align} \\min_{w, b} &amp;amp; \\ \\frac{1}{2}||w||^2 + C \\sum_{i=1}^N \\xi_i \\\\s.t. &amp;amp; \\ y_i(wx_i + b) \\ge 1 - \\xi_i \\\\ \\ &amp;amp; \\xi_i \\ge 0, \\ i = 1, 2,..., N \\\\\\end{align}\\]Applying the same methodology as the previous section, we get our final optimization problem\\[\\begin{align} \\min_{\\alpha} &amp;amp; \\ \\frac{1}{2} \\sum_{i=1}^N \\sum_{j=1}^N \\alpha_i \\alpha_j y_i y_j x_i x_j - \\sum_{i=1}^N \\alpha_i \\\\ s.t. &amp;amp; \\ \\sum_{i=1}^N \\alpha_i y_i = 0 \\\\ &amp;amp; \\ 0 \\le \\alpha_i \\le C, \\ i = 1,2,..., N \\\\\\end{align}\\]Non-linear SVMsSince when making decisions, we never use an input alone like $w x_i$. Instead, we calculate $w (x_i \\cdot x_j)$ We can take advantage of this by applying kernel trick.We map a data point $x_i$ from input space to a feature space through\\[z = \\phi(x)\\]We define the kernel function K as\\[K(x, z) = \\phi(x) \\phi(z)\\]where $x$ and $z$ are two elements in the input space.With the kernel function, the decision function can be written as\\[f(x) = \\text{sign}(\\sum_{i=1}^{N} \\alpha^* y_i K(x, x_i) + b^*)\\]And our optimization problem becomes the following\\[\\begin{aligned} \\min_{\\alpha} &amp;amp; \\frac{1}{2} \\sum_{i=1}^N \\sum_{j=1}^N \\alpha_i \\alpha_j y_i y_j K(x_i, y_j) - \\sum_{i=1}^N \\alpha_i \\\\ s.t. &amp;amp; \\ \\sum_{i=1}^N \\alpha_i y_i = 0 \\\\ \\ &amp;amp; 0 \\le \\alpha_i \\le C, \\ i = 1,2,..., N \\\\\\end{aligned}\\]Common Kernal FunctionsPolynomial Kernel Function\\[K(x, z) = (x \\cdot z + 1)^p\\]Gaussian Kernel Function\\[K(x, z) = \\exp(-\\frac{||x - z||^2}{2 \\delta ^ 2})\\]SMO Algorithm (TODO)The algorithm for solving the optimization problem." }, { "title": "SLM Chapter 6 Logistic Regression", "url": "/posts/C6-Logistic-Regression/", "categories": "Study Notes, Statistical Learning Methods", "tags": "machine learning, notes, maths, tutorials, english", "date": "2019-11-30 06:43:00 -0500", "snippet": "Logistic Distribution\\[F(x) = P(X \\le x) = \\frac{1}{1 + e^\\frac{-(x - \\mu)}{\\gamma}} \\\\f(x) = F&#39;(x) = \\frac{e^\\frac{-(x - \\mu)}{\\gamma}}{\\gamma(1 + e^\\frac{-(x - \\mu)}{\\gamma}) ^ 2}\\]where $\\mu$ controls the center of the distribution, and $\\gamma$ controls its sharpness (smaller $\\gamma$ means shaper curve)Logistic distribution and its CDFReal Value to ProbabilitySuppose you want to calculate how likely a sample $x$ belongs to class $k$. You calculate $z = w * x + b$ for some weight $w$ and bias $b$. The problem is, $z$ will be in range $(-\\infty, +\\infty)$, while we require it to be in $(0, 1)$. Here is the solutionFor some probability $p \\in (0, 1)$, we calculate its odds as\\[odds(p) = \\frac{p}{1-p}\\]where $odd(p) \\in (0, +\\infty)$. In real life, when we describe, let’s say, the chance of winning a lottery, we may say its ‘1 in 100000’. This is equivalent to saying that the probability $p$ of winning the lottery satisfies:\\[\\begin{aligned} odd(p) &amp;amp;= \\frac{\\text{chance of winning}}{\\text{chance of losing}} \\\\ &amp;amp;= \\frac{1}{100000 - 1}\\end{aligned}\\]We further map $(0, +\\infty)$ to $(-\\infty, +\\infty)$ by taking its log value, resulting in the logit function\\[logit(p) = log \\frac{p}{1-p}\\]Finally, we can let\\[logit(p) = w*x + b\\]Solve for $p$, we get\\[p = \\frac{1}{1 + e^{-(wx + b)}}\\]Chapter 6.2: Maximum Entropy ModelReferenceshttps://repository.upenn.edu/cgi/viewcontent.cgi?article=1083&amp;amp;context=ircs_reportsIdeaWhen a distribution can not be determined by the given evidence, we make a guess that maximizes the entropy of the distribution subject to the evidence as constraints.Solving for the maximum entropy model is actually an constraint optimization problem: we would like to maximize the entropy of our model while satisfying the constraint that our model has to match our observation.This is a discriminative model, i.e. estimates directly $p(y \\mid x)$ (as opposed to generative model, see chapter 1 for comparison).Set Up for Target FunctionWe let the entropy of $P(Y \\mid X)$ be:\\[\\begin{aligned} H(P) &amp;amp;= E_xH(y \\mid x) \\\\&amp;amp;= -\\sum_{x, y} \\tilde{p}(x)p(y \\mid x)\\ln(p(y \\mid x)) \\\\\\end{aligned}\\]where $\\tilde{p}(x)$ is the probability of $x$ (calculated by counting).$H(P)$ is then our maximization target.Set Up for ConstraintsFirst, for an input sentence $x$ and label $y$, we define feature function $f(x, y)$ as\\[f(x, y) = \\begin{cases} 1 \\text{ if x and y satisfies some assertions} \\\\ 0 \\text{ otherwise}\\end{cases}\\]For a problem, we may have multiple feature functions $f_1, f_2, …, f_n$.For example, consider filling in the following blank I will &amp;lt;BLANK&amp;gt; the piano when I get home.In the training set, we see many different phrases. For example, ‘The musician plays the piano’, ‘The shop sells the piano’, etc. We may define the following feature functions:\\[f_1(x, y) = \\begin{cases} 1 \\text{ if word &#39;play&#39; follows a person in x and y = &#39;play&#39; } \\\\ 0 \\text{ otherwise}\\end{cases}\\]\\[f_2(x, y) = \\begin{cases} 1 \\text{ if word &#39;play&#39; follows a place name in x and y = &#39;sell&#39; } \\\\ 0 \\text{ otherwise}\\end{cases}\\]It is then easy to see that the number of sentences where ‘play’ follows a person will then be $\\sum_{x, y}f_1(x, y)$.Therefore, the probability of observing such fact in the training set is\\[E_{\\tilde{p}(x,y)}f_1(x, y) = \\sum_{x,y} \\tilde{p}(x, y)f_1(x, y)\\]We define our model (estimation) as $p(y \\mid x)$. In our estimation, the probability of making such observation is\\[E_{p(x,y)}f_1(x, y) = \\sum_{x,y} \\tilde{p}(x)p(y \\mid x) f_1(x, y)\\]Note that we factorize $p(x,y)$ as $\\tilde{p}(x)p(y \\mid x)$.If our model is correct, we must have $E_{\\tilde{p}(x,y)}f_1(x, y)$ = $E_{p(x,y)}f_1(x, y)$ .Therefore, in our model $p(y \\mid x)$, for any feature function $f_i(x, y)$, we require that $E_{p(x,y)}$ is equal to $E_{\\tilde{p}(x,y)}$, i.e. our model (estimation) matches our observation of the data. This will be our constraints for our model (together with the constraint that our estimated distribution should sum to 1).Optimization ProblemWe need to optimize the entropy of our model $H(P)$ subject to constraints.The optimization problem can be expressed as the following:\\[\\begin{aligned}\\max_P &amp;amp; = -\\sum_{x, y} \\tilde{p}(x)p(y \\mid x)\\ln(p(y \\mid x)) \\\\\\text{s.t. } &amp;amp; E_p(f_i) = E_{\\tilde{p}}(f_i), i = 1,2,...,n \\\\&amp;amp; \\sum_y P(y \\mid x) = 1\\end{aligned}\\]Lagrange FunctionWe rewrite the above problem into a standard Lagrangian optimization problem\\[\\begin{aligned}\\min_P &amp;amp; = \\sum_{x, y} \\tilde{p}(x)p(y \\mid x)\\ln(p(y \\mid x)) \\\\\\text{s.t. } &amp;amp; E_p(f_i) - E_{\\tilde{p}}(f_i) = 0, i = 1,2,...,n \\\\&amp;amp; \\sum_y P(y \\mid x) = 1\\end{aligned}\\]We define the Lagrange function $L(p, w)$ as:\\[L(P, w) = - H(P) + w_0(1 - \\sum_y P(y \\mid x)) + \\sum_{i = 1}^n w_i(E_p(f_i) - E_{\\tilde{p}}(f_i))\\]and solve the following\\[\\frac{\\partial L(P, w)}{\\partial(P(y \\mid x))} = 0\\]See link to the detailed explanation on why we do this.The solution tells us that our model $P_w(y \\mid x)$ parametrized by $w$ will have the form\\[P_w(y \\mid x) = \\frac{1}{z_w(x)} e^{\\sum_i w_if_i(x, y)}\\]where $Z_w(x)$ is a normalization term calculated as\\[Z_w(x) = \\sum_y e^{\\sum_i w_i f_i(x, y)}\\]The only problem left now is finding the optimal parameter $w^*$ that maximizes $P_w(y \\mid x)$, i.e.\\[w^* = \\arg \\max_w P_w(y \\mid x)\\]which we leave to the all-mighty gradient-descent method." }, { "title": "SLM Chapter 5 Decision Trees", "url": "/posts/C5-Decision-Trees/", "categories": "Study Notes, Statistical Learning Methods", "tags": "machine learning, notes, maths, tutorials, english", "date": "2019-11-24 21:20:00 -0500", "snippet": "IdeaEach node is a decision maker. It splits a set of data into several sub-sets according to some criterion, and passes each sub-group to its corresponding child node. A class label is given to each leaf node, where no further decisions are made. When predicting the label of a new sample, we let the sample travel from the root node to a leaf node, following the decision rules along its way. When it reaches a leaf node, we assign the label of the leaf node to this sample.The idea is demonstrated by the following pseudo code:def buildNode(dataset: List[Sample]): # We first comeup with a criterion with the dataset criterion = get_criterion(dataset) # Criterion: Sample -&amp;gt; Int # If we find out that we don&#39;t need to further split the dataset, # we may stop here and return a leaf node. stop, label = should_stop(dataset, criterion) if stop: return Node(None, label=label) # Then we create one subset for each criterion subsets = [[] for _ in range(criterion.k_children)] for sample in dataset: kth = criterion(sample) subsets[kth].append(sample) # Recursively build child nodes children = [build_node(subsets[i]) for i in range(k_children)] # Call the constructor to create current node node = Node(children, criterion) return nodeIntuitionsA decision tree can be seen as a series of if-then statements.It is highly interpretable.It trains very quickly.BackgroundConditional EntropyConditional entropy $H(Y \\mid X)$ is defined as the expectation of the entropy of $Y$ when X is given a specific value. Mathematically:\\[\\begin{align}H(Y \\mid X) &amp;amp;= \\sum_{x \\in X} p(x)H(Y \\mid X = x) \\\\&amp;amp;= - \\sum_{x \\in X} p(x) \\sum_{y \\in Y} p(y \\mid x) \\log p(y \\mid x) \\\\&amp;amp;= - \\sum_{x \\in X} \\sum_{y \\in Y} p(x,y) \\log p(y \\mid x) \\\\&amp;amp;= - \\sum_{x \\in X} \\sum_{y \\in Y} p(x,y) \\log \\frac{p(x, y)}{p(x)} \\\\&amp;amp;= - \\sum_{x \\in X} \\sum_{y \\in Y} p(x,y) \\log p(x, y) - (- \\sum_{x \\in X} \\sum_{y \\in Y} p(x,y) \\log p(x)) \\\\&amp;amp;= - \\sum_{x \\in X} \\sum_{y \\in Y} p(x,y) \\log p(x, y) - (- \\sum_{x \\in X} p(x) \\log p(x)) \\\\&amp;amp;= H(X, Y) - H(X)\\end{align}\\]ComponentsDecision tree learning usually involves three steps: feature selection decision tree generation pruningFeature SelectionAt each step, we need to decide how to divide a data set into subsets, i.e. implementing get_criterion function used in the pseudo code above. Usually, a criterion is something like:def someExampleCriterion(sample): if sample.x &amp;lt; 1: return 1 elif 1 &amp;lt;= sample.x &amp;lt; 5: return 2 else: # sample &amp;gt;= 5: return 3Therefore, we need to decide the following: How many subsets do we need to create? There are 3 different return values for this example criterion, but why not make it 4, 5 or even 42? Which feature do we use? In the example, we use sample.x, but why not sample.y? What are the points of split? We use 1 and 5 in the example, but why not 2 and 4, or 10 and 100?A criterion will be uniquely determined by the three questions above. The thing is, how do we know if an answer to the questions is good or bad?Maximizing Information GainDefinitionWe can make a judgment by using information gain. We consider an answer with a larger information gain to be better.For a given data set $D$ and an answer (i.e a criterion) $A$, information gain is defined as follows:\\[\\begin{aligned}g(D, A) &amp;amp;= H(D) - H(D \\mid A) \\\\&amp;amp;= H(D) - \\sum_{i=1}^N \\frac{|D_i|}{|D|} H(D_i)\\end{aligned}\\]where $N$ is the number of subsets produced by the criterion $A$, $D_i$ is the $i$th of the $N$ subsets $H(D)$ is the empirical entropy of the data set $D$ calculated as\\[\\begin{aligned}H(D) &amp;amp;= - \\sum_{k=1}^{K} \\hat p_k \\log \\hat p_k \\\\&amp;amp;= - \\sum_{k=1}^{K} \\frac{|C_k|}{|D|} \\log \\frac{|C_k|}{|D|}\\end{aligned}\\] Note that we use $\\hat p_k$ to represent the empirical probability that a sample in $D$ has a label $k$. This is calculated by counting, i.e. dividing $|C_k|$ (the number of samples labeled $k$) by $|D|$ (the total number of samples in $D$).Intuitively, the best split of a data set $D$ should reduce the chaos (entropy) of the data set by the largest amount. Finding a split $A$Following the discussion above, our goal is to find a split $A$ such that\\[A = \\arg \\max_{\\hat A \\in S} g(D, \\hat A)\\]where $S$ is the search space for $A$.We can first design such a search space. For example, we may do this with a grid search:def get_criterion(): best_split = None for feature in all_features: for num_child in range...: for split_point in range... calculate_information_gain(...) best_split = update_best(...) def criterion(sample): ...split using the best_split variable return criterionProblemInterestingly, the resulting criterion $A$ will always favor the ones with a large number of children. Consider a criterion that creates a subset for every single sample. This is guaranteed to produce a maximum information gain by completely eliminating the entropy after the split, i.e. $H(D \\mid A) = 1\\log1 \\sum0\\log0 = 0$.This is meaning less, and we need to punish the model for creating too many subsets.Maximizing Information Gain RatioInstead of finding A with the following\\[A = \\arg \\max_{\\hat A \\in S} g(D, \\hat A)\\]we use\\[\\begin{aligned}A &amp;amp;= \\arg \\max_{\\hat A \\in S} g_R(D, \\hat A) \\\\&amp;amp;= \\frac{g(D, A)}{H_A(D)} \\\\&amp;amp;= \\frac{g(D, A)}{- \\sum_{i=1}^N \\frac{|D_i|}{|D|} \\log \\frac{|D_i|}{|D|}}\\end{aligned}\\]where $n$ is the number of subsets of $D$ created by criterion $A$, and $D_i$ is the $i$th subset.Minimizing Gini IndexThis is used by CART algorithm during classification to find an optimal criterion.Just like entropy, Gini index measures how chaotic a probability distribution is.For a classification problem with $K$ classes, if we let $p_k$ be the probability for a sample to be in class $k$, and $p = {p_1, p_2,…,p_k}$, the Gini index will be\\[\\text{Gini}(p) = \\sum_{k=1}^{K}p_k(1-p_k)\\]In fact, Gini index is an approximation for the entropy if we consider substituting $log$ with its first order Taylor expansion (i.e. $\\ln (x) \\approx x - 1$ at $x \\approx 1$)\\[\\begin{aligned}H(p) &amp;amp;= - \\sum_{k=1}^{K} p_k \\log p_k \\\\ &amp;amp; \\approx -\\sum_{k=1}^{K} p_k f(p_k) \\\\ &amp;amp; \\approx - \\sum_{k=1}^{K} p_k (f(1) + f&#39;(1)(p_k - 1)) \\\\&amp;amp;= - \\sum_{k=1}^{K} p_k(p_k -1) \\\\&amp;amp;= \\sum_{k=1}^{K} p_k(1 - p_k) \\\\&amp;amp;= \\text{Gini(p)}\\end{aligned}\\]We select a feature $A$ as\\[\\begin{aligned}A &amp;amp;= \\arg \\min_{\\hat A \\in S} \\text{Gini}(D, \\hat A) \\\\&amp;amp;= \\arg \\min_{\\hat A \\in S} \\sum_{i=1}^N \\frac{|D_i|}{|D|} \\text{Gini}(D_i) \\\\\\end{aligned}\\]where $N$ is the number of subsets of $D$ created by criterion $A$, and $D_i$ is the $i$th subset.Gini index can be calculated faster than entropy, since it does not involve $\\log$ operators.Minimizing Square LossThis is used by CART algorithm during regression.Recall the fact that a decision tree divides the sample space $R$ into multiple sub-regions $R_1, R_2, …, R_M$, with each node representing one region. During regression, instead of assigning a class label to each region $R_m$, we assign a continuous value $c_m$ to the region, so that when making predictions, we predict output $c_m$ for every sample in region $R_m$.We can then find the best split by minimizing the square loss:\\[\\begin{aligned}A &amp;amp;= \\arg \\min_{\\hat A \\in S} \\text{SquareLoss}(D, \\hat A) \\\\&amp;amp;= \\arg \\min_{\\hat A \\in S} \\sum_{i=1}^N (y_i - f(x_i))^2 \\\\&amp;amp;= \\arg \\min_{\\hat A \\in S} \\sum_{i=1}^N (y_i - \\sum_{m=1}^M c_mI(x \\in R_m))^2 \\\\\\end{aligned}\\]where $I$ is the indicator function, $N$ is the number of samples, $M$ is the total number of subregions, and $c_m$ can be calculated as the average output $\\bar y$ of all samples in region $m$If we limit the decision tree to be a binary tree, i.e. $M = 2$, then we only need to iterate through the split point and the features to use.Decision Tree GenerationSee the pseudo code in the Idea section.We further fill in the details of the shouldStop function:def should_stop(dataset, criterion): if all samples in dataset have same label: return True, label if calc_information_gain(dataset, criterion) &amp;lt; 0.01 # Just an example. The threshold can be passed in as a parameter return True, max_vote(dataset) return False, NoneDecision Tree PruningWe define a loss function $C_{\\alpha}(T)$ for a decision tree $T$\\[\\begin{aligned}C_{\\alpha}(T) &amp;amp;= C(T) + \\alpha|T| \\\\&amp;amp;= \\sum_{t=1}^{|T|}N_tH_t(T) + \\alpha |T|\\end{aligned}\\]where $|T|$ is the number of leaf nodes, $N_t$ is the number of nodes in leaf node $t$ and $H_t$ is the empirical entropy at node $t$. For each leaf node, we calculate the loss of the entire tree before and after the node is merged into its parent. If we result in a smaller loss, we do the pruning. We repeat the process until there is no leaf node that can be pruned.AlgorithmsID3See the pseudo code. For each node, it chooses a split that maximizes the information gain.CD4.5Same as ID3 except that it maximizes information gain ratio instead.CARTShort for classification and regression tree.It is a binary tree.It uses Gini index during classification, and Square loss during regression. Plus, it uses a special pruning technique.CART PruningRecall the loss function of a tree $T$\\[\\begin{aligned}C_{\\alpha}(T) &amp;amp;= C(T) + \\alpha|T| \\\\\\end{aligned}\\]and we further define the loss of a node $C_\\alpha(t)$ as the loss if we merge all of its children into itself (i.e. the loss of this node we would get if we end the tree there). In other words, for a subtree $T_t$ rooted at $t$, the loss before pruning is $C_\\alpha (T)$ (smaller classification loss, larger punishment for model complexity) and the loss after pruning is $C\\alpha(t)$ (larger classfication loss, almost no punishment for model complexity). Therefore, if $C_a(t) &amp;gt; C_a(T)$, meaning we’d rather not add child nodes and make the prediction right at the node $t$, we will decide to prune. The alpha threshold is the value of $\\alpha$, for which we do not care whether we prune or not (as they result in the same amount of loss). The threshold $\\alpha$ satisfies\\[\\begin{aligned}C_\\alpha (t) &amp;amp;= C_\\alpha (T_t) \\\\C(t) + \\alpha * 1 &amp;amp;= C(T_t) + \\alpha |T_t| \\\\\\alpha &amp;amp;= \\frac{C(t) - C(T_t)}{|T_t| - 1}\\end{aligned}\\]Not surprisingly, when $\\alpha$ is small enough, we will never choose to prune. As we slowly increase $\\alpha$, we will find more and more ‘prunable’ nodes. We increase the $\\alpha$, get new pruned trees by pruning all ‘prunable’ nodes, and save them separately. In the end, we select the best one of the pruned trees using cross validation.The pseudo code is the following:def get_all_pruned_trees(tree):all_trees = []alpha = +infcurr_tree = deep_copy(tree)while curr_tree has more than 2 levels: # Get the minimum alpha value in current tree for node in traverse(curr_tree): alpha = min(alpha, getAlphaThreshold(node)) # Prune the nodes with the min alpha values # function `prune` should modify `curr_tree` for node in traverse(curr_tree): if (getAlphaThreshold(node) == alpha): prune(node) # Save the tree for as a candidate for cross validation all_treee.append(deep_copy(curr_tree))" }, { "title": "SLM Chapter 4 Naive Bayes", "url": "/posts/C4-Naive-Bayes/", "categories": "Study Notes, Statistical Learning Methods", "tags": "machine learning, notes, maths, english", "date": "2019-11-08 06:18:00 -0500", "snippet": "A generative learning model.AssumptionGiven a class label, each feature of a data point should be independently distributed.Specifically, for any data point $x_i=(x_i^{(1)}, x_i^{(2)},…, x_i^{(n)})$ and any class $c_k \\in {c_1, c_2, …, c_K} $\\[P(x_i|c_k) = P(x_i^{(1)}, x_i^{(2)},..., x_i^{(n)} \\mid c_k)\\]should factorize to\\[\\begin{align}P(x_i|c_k) &amp;amp;= P(x_i^{(1)} \\mid c_k)P(x_i^{(2)} \\mid c_k)...P(x_i^{(n)} \\mid c_k) \\\\&amp;amp;= \\prod_{j=1}^{n}P(x_i^{(j)} \\mid c_k) \\end{align}\\]AlgorithmFollowing the assumption and basic Bayesian rule, we derive the following\\[\\begin{align}P(c_k|x) &amp;amp;= \\frac{P(x \\mid c_k) P(c_k)}{P(x)} \\\\&amp;amp;= \\frac{\\prod_{j=1}^{n} P(x^{(j)} \\mid c_k) P(c_k)}{\\sum_{k=1}^K P(x, c_k) P(c_k)} \\\\&amp;amp;= \\frac{\\prod_{j=1}^{n} P(x^{(j)} \\mid c_k) P(c_k)}{\\sum_{k=1}^K \\prod_{j=1}^{n}P(x^{(j)} \\mid c_k) P(c_k)}\\end{align}\\]For $k=1,2,…,K$, we estimate $P(c_k)$ simply by counting the training set\\[P(c_k) = \\frac{\\text{samples in class k}}{\\text{training set size}}\\]We could also model $P(c_k)$ as a Dirichlet distribution (a multi-dimensional beta distribution).We then model $P(x \\mid c_k)$ as well. One way of doing it when the feature space is discrete is\\[P(x \\mid c_k) = \\frac{\\text{number of samples in class k that has a particular value}}{\\text{number of samples in class k}}\\]Plug everything in, and can then make our prediction by calculating\\[y = \\arg \\max_{c_k} P(c_k \\mid x) \\\\= \\arg \\max_{c_k} \\prod_{j=1}^{n} P(x^{(j)} \\mid c_k) P(c_k)\\]Laplacian smoothing$P(c_k)$ and $P(x \\mid c_k)$ are likely to be zero if some particular value is never observed. This happens when there are too many classes and features while having too little training samples.To solve this issue, we add a smoothing term $\\lambda &amp;gt; 0$ to the numerator. We add some multiple of $\\lambda$ to the denominator to normalize the probability." }, { "title": "SLM Chapter 3 K-Nearest-Neighbor", "url": "/posts/C3-KNN/", "categories": "Study Notes, Statistical Learning Methods", "tags": "machine learning, notes, maths, english", "date": "2019-11-07 09:16:00 -0500", "snippet": "A supervised learning model.Find the nearest K neighbors of a data point, assign according to majority vote.The value K needs to be fine-tunedProperties Needs a distance measure between two points $x_i=(x_i^{(1)}, x_i^{(2)},…, x_i^{(n)})$ and $x_j=(x_j^{(1)}, x_j^{(2)},…, x_j^{(n)})$\\(L_p(x_i, x_j) = (\\sum^n_{l=1}|x^{(l)}_i - x^{(l)}_j|^{p})^{\\frac{1}{p}}\\) A non-parametric model, i.e. need to keep the entire dataset in order to make predictions. K-Dimensional Trees (K-d Trees) A binary tree. Each node is a partition of the k-dimensional space.MotivationFor each new point to be predicted, we first need to find its K nearest neighbors. This cannot be done efficiently without using some smart data structures.Implementationfrom math import sqrtclass KDTreeNode: def __init__(self, decision_dim, value, left=None, right=None): self.value = value self.left = left self.right = right self.decision_dim = decision_dim def printSelf(self): print(self) def __repr__(self): str_left = str(self.left) if self.left is not None else &quot;&quot; str_right = str(self.right) if self.right is not None else &quot;&quot; return str_left + str(self.value) + str_rightclass KDTree: def __init__(self, dim): self.root = None self.dim = dim def insert(self, point): assert len(point) == self.dim if self.root is None: self.root = KDTreeNode(0, value=point) else: node = self.root while True: dim = node.decision_dim # The point lies on the decision surface # if point[dim] == node.values[0][dim]: # node.values.append(point) # return # The point should be in its left subspace if point[dim] &amp;lt;= node.value[dim]: if node.left is None: node.left = KDTreeNode((dim + 1) % self.dim, point) return node = node.left # The point should be in its right subspace else: if node.right is None: node.right = KDTreeNode((dim + 1) % self.dim, point) return node = node.right def getClosestN(self, target, n=1): &quot;&quot;&quot; Reference: https://www.colorado.edu/amath/sites/default/files/attached-files/k-d_trees_and_knn_searches.pdf &quot;&quot;&quot; if self.root is None: return None closestN = [] # [(point, distance)], sorted by distance stack = [] # [(node, left_used, right_used)] node = self.root nth_closest = float(&#39;inf&#39;) # Current nth closest distance # Locate the finest subspace (i.e. a leaf node), and record the path along the way while True: dim = node.decision_dim if target[dim] &amp;lt;= node.value[dim]: stack.append([node, True, False]) if node.left is None: break node = node.left else: stack.append([node, False, True]) if node.right is None: break node = node.right # Search while stack: node, left_used, right_used = stack[-1] print(node.value, left_used, right_used) dim = node.decision_dim # Ignore the node if already used, or too far away to contain any closer point. if ((left_used or node.left is None) and (right_used or node.right is None)) or \\ abs(node.value[dim] - target[dim]) &amp;gt; nth_closest: updateMinimum(closestN, n, node.value, calculateDistance(target, node.value)) nth_closest = closestN[-1][1] stack.pop() continue # Check left subspace if not left_used and node.left is not None: # Set left as used stack[-1][1] = True # Append child node and check its distance stack.append([node.left, False, False]) # Check right subspace elif not right_used and node.right is not None: # Set right as used stack[-1][2] = True # Append child node and check its distance stack.append([node.right, False, False]) else: stack.pop() return closestN def printSelf(self): if self.root is not None: self.root.printSelf() def __str__(self): return str(self.root)def updateMinimum(array, n, point, distance): # Assume that n is small enough so that we don&#39;t have to bother about performance... # Although using a heap would be ideal... length = len(array) assert length &amp;lt;= n array.append((point, distance)) array.sort(key=lambda p: p[1]) if len(array) &amp;gt; n: array.pop()def calculateDistance(x, y): assert len(x) == len(y) square_dist = 0 for v1, v2 in zip(x, y): square_dist += (v1 - v2) ** 2 return sqrt(square_dist)print(&quot;Checking insertion&quot;)points = [(7,2),(5,4),(9,6),(2,3),(4,7),(8,1)]# points = reversed([(2,3,1), (5,4,2), (9,6,3), (4,7,4), (8,1,5), (7,2,6)])tree = KDTree(2)for p in points: tree.insert(p)print(tree)print(&quot;Checking query algorithm&quot;)points = [(3, 6), (17, 15), (13, 15), (6, 12), (9, 1), (2, 7), (10, 19)]tree = KDTree(2)for p in points: tree.insert(p)print(tree.getClosestN((4,8), n=3))" }, { "title": "SLM Chapter 2 Perceptron", "url": "/posts/C2-Perceptron/", "categories": "Study Notes, Statistical Learning Methods", "tags": "machine learning, notes, maths, english", "date": "2019-11-06 08:56:00 -0500", "snippet": "Essentially a hyperplane that divides the space into two classes.Properties A linear and binary classifier. A discriminative (as apposed to generative) model. The hypothesis space is $\\mathcal{F} = {f\\mid f(x) = w x + b; w, b \\in \\mathbb{R}^n}$. Can only be applied when training data is Linearly separable.AlgorithmPredictionFor a data point, calculate $y = sign(w x + b)$ , where $sign$ is the sign function (outputting either -1 or 1, depending on the sign of its input).Loss FunctionLoss is calculated based on the distance between a misclassified data point and the hyperplane:\\(L(w, b) = -\\sum_{(x_i,y_i) \\in M}y_i(wx_i+b)\\)where $M$ is the set of all misclassified data points.Compared to the original distance measure\\(Distance = \\frac{1}{||w||} |wx_i+b|\\)the loss function Summed over the misclassified points of the entire data set. Multiplied a $y_i$ term to remove the absolute value operator, so that the loss function is differentiable. Removed $\\frac{1}{||w||}$, and consider only the functional margin (see chapter 7). Optimization The goal is to find parameters $w$ and $b$ such that\\(w, b = \\arg\\min_{w,b}L(w, b)\\)Each step, we update using gradient descent \\(w \\leftarrow w - \\eta \\nabla_w L(w, b) \\\\b \\leftarrow b - \\eta \\nabla_b L(w, b)\\)or \\(w \\leftarrow w + \\sum_{(x_i,y_i) \\in M} \\eta y_i x_i\\\\b \\leftarrow b + \\sum_{(x_i,y_i) \\in M} \\eta y_i \\\\\\)We can also consider updating one point at a time: for every step, we sample $(x_i, y_i)$ from M and do\\(w \\leftarrow w + \\eta y_i x_i\\\\b \\leftarrow b + \\eta y_i \\\\\\)We repeat the update until convergence.Dual PerceptronsIf we repeat the above process, we will get our final (and optimal) parameters $\\hat w$ and $\\hat b$ calculated as follows\\(\\hat w = w_0 + \\eta x_iy_i + \\eta x_jy_j + \\eta x_ky_k... \\\\\\hat b = b_0 + \\eta y_i + \\eta y_j + \\eta y_k...\\)where $i, j, k, …$ are each a misclassified data point that we choose in each step.The above can be written as\\(\\hat w = w_0 + \\sum_{i=1}^N \\alpha_i x_iy_i \\\\\\hat b = b_0 \\sum_{i=1}^N \\alpha_i y_i \\\\\\)where $\\alpha_i$ shows how often a point $(x_i, y_i)$ gets picked. Following our calculation, the value of each $\\alpha$ should be some integer multiple of $\\eta$.IdeaSuppose we have $D$ features and $N$ training samples.By observation, we see that for each step, we need to find out misclassified points, which involves calculating $wx_i + b$ for $i = 1, 2,…,N$. The calculation takes $O(ND)$ time.If we use the dual form, each step we calculate $\\alpha_i x_i y_i x_j + \\alpha_i y_i$ for $i = 1, 2,…,N$. By pre-computing a Gram matrix $G = |x_i \\cdot x_j |_{N \\times N}$, the calculation will be driven down to $O(N)$ time.PredictionSimply plug $w$ and $b$ in:\\(f(x) = sign(\\sum_{i=1}^N (\\alpha_i x_i y_i x + \\alpha_i y_i))\\)OptimizationWe initialize $\\alpha = (\\alpha_1, \\alpha_2, …, \\alpha_N)$ as an all-zero vector (meaning none of the data points have been picked).For each misclassified point $(x_i, y_i)$, we do\\(\\alpha_i \\leftarrow \\alpha_i + \\eta \\\\b \\leftarrow b + \\eta y_i\\)" }, { "title": "SLM Chapter 1 Introduction", "url": "/posts/C1-Introduction/", "categories": "Study Notes, Statistical Learning Methods", "tags": "machine learning, notes, maths, english", "date": "2019-11-03 03:46:00 -0500", "snippet": "This is a series of learning notes that I made when reading the book Statistical Learning Methods（统计学习方法) by Li, Hang(李航).Elements of Statistical LearningModelA model $f$ is chosen from a hypothesis space $\\mathcal{F} = {f\\mid Y = f_\\theta(x), \\theta \\in \\mathbb{R}^n} $, or $\\mathcal{F} = {P\\mid P = P_\\theta(Y\\mid X), \\theta \\in \\mathbb{R}^n} $ (i.e. a set of all possible models that is used), where $\\theta$ is the parameter that determines a model $f$.StrategyThe evaluation criterion of any candidate model $f$.AlgorithmHow to find the best model in $\\mathcal{F}$ according to our strategy (i.e. how to solve the optimization problem).Types of ModelsThere are multiple ways to classify models.Probabilistic vs. DeterministicThese two can be converted to each other. Outputting the maximum of a probabilistic distribution gives a deterministic outcome, and normalizing a deterministic outcome gives a probabilistic prediciton.ProbabilisticWe learn a probability distribution as the final outcome. Specifically: In supervised learning, for each sample $x$, we learn a probability distribution of the prediction outcome $y$, i.e. we learn $P(y\\mid x)$. In unsupervised learning (classification without knowing how many classes are there), we learn both $P(x\\mid z)$ (probability of getting a sample given that it comes from a class, represented by $z$) and $P(z \\mid x)$ (probability of the given sample belonging to a certain class $z$).DeterministicIn both scenarios, we try to predict the most likely outcome (a certain output vector), instead of getting a probability distribution. In supervised learning, we learn a function $y = f(x)$ In unsupervised learning, we learn $z = g(x)$Linear vs. Non-LinearEasy.Parametric vs. Non-ParametricParametric LearningThe model is uniquely identified by all of its parameters (e.g. a neural network). It is fixed and finite-dimensional.Non-Parametric LearningThe complexity, or the parameters of the model grows with the size of the dataset (e.g. SVM, KNN).Model Selection and EvaluationExpected risk $E_p$ of a model is\\[\\begin{align*}R_{exp}(f) &amp;amp;= E_p[L(Y, f(X))] \\\\ &amp;amp;= \\int{L(y, f(x))P(x, y)dxdy}\\end{align*}\\]where $L$ is a loss function. There are many different choices for $L$, for example, L1 loss, L2 loss and log-likelihood loss. Our goal is to find a model $f$ such that\\[f = \\min_{f \\in \\mathcal{F}}{R_{exp}(f)}\\]Yet, we cannot calculate $R_{exp}(f)$ directly since we do not know $P(x, y)$ (which actually requires learning). We cannot work out $P(x,y)$ first either, because $P(x,y)$ is the very thing that we need to learn.To make the problem viable, we minimizes the empirical risk instead of the Expected risk:\\[\\begin{aligned}f &amp;amp;= \\min_{f \\in \\mathcal{F}}{R_{emp}(f)} \\\\ &amp;amp;= \\min_{f \\in \\mathcal{F}} \\frac{1}{N} \\sum^N_{i=1}{L(y_i, f(x_i))}\\end{aligned}\\]When sample size $N$ becomes large enough, the empirical risk will approach expected risk.However, when $N$ is small, we may consider minimizing the structural risk instead for better performance\\[\\begin{aligned}f &amp;amp;= \\min_{f \\in \\mathcal{F}}{R_{srm}(f)} \\\\ &amp;amp;= \\min_{f \\in \\mathcal{F}} \\frac{1}{N} \\sum^N_{i=1}{L(y_i, f(x_i))} + \\lambda J(f)\\end{aligned}\\]Where $J$ is a function that grows as the model $f$ becomes more complex. E.g. when $f$ is parametrized by $\\theta$, we can use $J(f) = \\frac{1}{2}||\\theta||^2$Generalization Error BoundLet the real risk (generalization error) of our learned model $\\hat f$ and its estimation (empirical risk) be\\[R(\\hat f) = E[L(Y, \\hat f(X))]\\]\\[\\hat R(\\hat f) = R_{emp}(\\hat f) = \\frac{1}{N} \\sum^N_{i=1}{L(y_i, \\hat f(x_i))}\\]For a finite hypothesis space $\\mathcal{F}$ of size $d$, we have\\[P(R(f) \\le \\hat R(f) + \\epsilon(d, N, \\delta)) &amp;gt;= 1 - \\delta\\]Where $N$ is the size of the training set, $0 \\lt \\delta \\lt 1$, and $\\epsilon = \\sqrt{\\frac{1}{2N}(\\log{d} + \\log{\\frac{1}{\\delta}})}$(i.e. The generalization is bounded by the empirical risk. The more training samples you have and the smaller the hypothesis space $\\mathcal{F}$ is, the tighter the bound will be.The proof is done using the Hoeffding equation.Approaches: Generative vs. DiscriminativeReferencehttps://www.cnblogs.com/rossiXYZ/p/12244760.htmlGenerative ApproachLearns $P(Y|X)$ by using\\[P(Y|X) = \\frac{P(X,Y)}{P(X)}\\]Once the model is learned, we can usually reconstruct $P(X, Y)$, i.e. we can generate samples that resembles what the model has seen.DiscriminativeCalculates directly $Y = f(x)$ or $P(Y|X)$." }, { "title": "小爪的故事", "url": "/posts/fox/", "categories": "Writing", "tags": "creative, writing, personal, chinese", "date": "2017-11-10 09:24:00 -0500", "snippet": "" }, { "title": "小骷髅（一篇同人文）", "url": "/posts/skull/", "categories": "Writing", "tags": "creative, writing, personal, chinese", "date": "2016-02-15 21:46:00 -0500", "snippet": "​ 小骷髅独自坐在雪域的岸边，低头看水。尖锐的风已经使他的身体麻木，他大概感觉不到他的两条腿浸泡在温暖又平和的海水里。​ 水被小骷髅的腿搅动，开心得“喀啦啦”，“喀啦啦”地笑，裸露在空气里的年轻的骨头相互摩擦、挤压，发出的竟也是差不多的声音。​ “孩子，你从哪里来？”只有半个人高的雪人一蹦一蹦地跳过来，蹲坐在小骷髅身边。​ 小骷髅撇了他一眼，轻轻叹了口气。​ 雪人伸出粗壮的手臂挠挠脑袋。很好奇的样子，盯着他看。​ “你是从那上面下来的吧！”雪人问道。​ 小骷髅点了点头。​ “那你应该高兴啊！你知道多少顺着河下来的人都落到皮亚奴斯的洞穴里去再也没出来吗？”​ “一个小屋子里的婆婆已经把什么都告诉我了。”小骷髅终于开口了，“可是我有点想去见见它。”​ “你在想什么呢孩子！”雪人伸出手，但是触碰到小骷髅的一瞬间，异乎寻常的寒气刺得他一下子把手缩了回来。“你可真是一个让人感到奇怪的孩子啊。你从哪里来？”​ “一个很美很美的村子。”小骷髅仰首望天，似乎眼前就是那既让他怀念又让他害怕的东西。“我所知道的一切都是从那里开始，关于这个世界、关于人们、关于我的……我的……生……生命……”说到这里，小骷髅像是愣住了一样，脸颊两侧的骨头开始扭曲，上下颚的骨头也开始颤抖。他大概是要流泪了，可惜他没有承载那种液体的眼睛。​ 雪人完全不知道该如何安慰这样一个孩子，只好静静地蹲坐在他旁边。​ 许久，小骷髅的心情稍微平缓了些，继续说道：“我不知道还该不该称自己是生命。从前我和他们一起生活在村子里的时候，我觉得大家都是一样的小孩子。我们每天一起去听老教授讲药草的知识，下课以后去湖边郊游，我们可以调出用来吸引各种各样漂亮昆虫的药水。晚上我们可以在公园的大雕像下面一起看星星，养很多宠物的大叔那里有听不完的故事。总之，每天都很开心。”​ “那后来呢？”雪人问道。​ “我们慢慢长大，慢慢发现我们之间巨大的差别。一开始我以为我擅长魔法，森林里的精灵们教我的我一学就会。我是第一个能够用魔法帮助他们搬很重东西的孩子。但是后来，其他孩子都追上来了，他们也都学得很快，于是我在这方面就显得很平庸，甚至，很差劲。”​ “那有什么关系？”雪人终于觉得自己能够稍微开导一下这个孩子了。“人们总是有自己擅长的和不那么擅长的东西的。你在其他方面一定比别人优秀！”​ 小骷髅很认真得摇着脑袋：“我那时候也是这么想的。我在药草课上的成绩确实数一数二。不过后来我又发现，那并不值得骄傲，因为任何人只要想用这方面的知识，就可以从那本工具书上找到全部他想要的东西，即便没有学习过任何这方面知识的人也可以做出和我一样的东西来。”​ “可是那又怎么样呢？总有值得你骄傲的东西的。”雪人试图用豁达的态度感染他。​ “我想，我可能比他们更善于想象。”​ “对，这很好呀！”​ “但是后来我渐渐发觉，我的想象并没有太大的意义。我有时候不切实际地想象世界上不存在的人和物，有时候自得其乐地想象一些场景和对话，有时候还傻乎乎地想自己到底是谁，在这个世界上应该做什么，因此浪费了很多时光。这些，其他的孩子也都会想，不过他们可以控制自己什么时候想，什么时候不想，而且，他们比我更善于把想象付诸行动。”​ “没必要这样否定自己。” 雪人劝道。​ “可是事情总是那么糟糕。每当我发现一样自己独特的能引以为傲的长处，或者说，一个能让我满足地生活下去的理由的时候，它就会很快离我而去。我满足于每个周五能见到那个很有趣的小女孩，但是后来她去了别的地方；我满足于朝夕陪伴我的朋友，但是后来我们因为各自不同的生活和理想越走越远；我满足于自己所获得的知识，但是与别人相比，我知道的实在太少太少；我满足于村子里富有温情又单纯的人际关系，但是后来我慢慢发现每个人背后都有复杂的经历，他们带有目的性的思想总是隐蔽在客气的笑容之下。”​ 雪域的风声占据了舞台，填补对话的空白。​ “不管怎么样，你还拥有你的生命啊！”雪人终于用这个来打破僵局了。​ “这就是那最后一根稻草了。我以为这样想会救我，没想到反而让它把我给压垮了。”​ “怎么会这样？”​ “我想，我每天都可以见到阳光下的可爱的森林，见到森林里的小动物。生命让我觉得安心，让我觉得生活是充满意义的。我太想去看看这个世界到底是什么样的了。那天我第一次偷偷地跑到离村子很远的一座光秃秃的山上。路上我遇到了一个旅行者，他吓得转身就跑，一不小心被绊倒了。我还不知道他为什么这么害怕，但是从那以后，我就开始意识到我和他们真正的不同了：我没有父母，我不知道自己从哪里来，甚至，我没有一副完整的躯壳。我理解了为什么村子里的人总是特别照顾我，总是用很怜悯的眼光看我。村子外的人，被我的样子吓到，也是理所当然的了。——我是连生命都没有，还有什么让我对世界抱有期待呢？”​ 小骷髅接着说：“我从来不会饿，也从来不会渴，我也感觉不到冷和热，也没有体验过疼痛。因为我没有生命，世界不会接纳我，我只能到处流浪。”​ “可是我还是不懂，你为什么不继续呆在村子里呢？”雪人问道。​ “我想，我的存在与否对他们的生活一点影响也没用。我不想再无端地接受他们的怜悯了。我不值得他们为我付出那么多的关注。我根本称不上是一条生命。”​ 又是风凄苦的独奏。​ “我觉得水下有一颗和我很像很像的心。”小骷髅突然说道。​ “别傻了，下面是老鱼王皮亚奴斯。”​ “可是这水让我有一种温暖的感觉。或者说，是一种共鸣。这是我第一次有这样的感觉……这水为什么这么温暖呢？”​ “不知道。”​ “皮亚奴斯每天都做些什么呢？”​ “不知道。”​ “他有朋友吗？”​ “我们都没有见过他，怎么会知道这些呢！”雪人粗壮的手臂又开始不停地挠头了。​ “我觉得它很可怜。”​ “孩子啊！”雪人说道，“你这么有同情心，怎么还说自己没有生命呢！”​ “同情心，那是什么？”小骷髅第一次听说这个名词。​ “这……”雪人思考了好一会儿才知道该怎么解释。“这是你需要学会去控制的本能。”​ “因为你有生命，你才有这个本能，自然而然地觉得他很可怜。但是对生命来说，更重要的是抑制。你应该学会抑制，不管是对恶人的同情，还是不恰当的自卑。”​ 小骷髅若有所思地点了点头。“恶人，可是它真的恶吗？”​ “我们总是更愿意先去相信更坏的可能。事实是什么，你可以不去了解。要知道，一旦试图做出改变，现状可能就会变得难能可贵。不过你也可以带着必死的觉悟去探索，这是你的自由，极少数的人的确会愿意为了真相付出惨痛的代价。——不管怎样，我可以说，你确实是一条鲜活的生命，而且是我见过的最最独特的一条。”" }, { "title": "中秋的传说", "url": "/posts/the-moon/", "categories": "Writing", "tags": "creative, writing, personal, chinese", "date": "2015-09-17 22:14:00 -0400", "snippet": "​ 话说嫦娥偷吃了仙丹，即将奔月成仙。​ 月亮听说以后可高兴坏了，慌忙找人在自己肚子上盖了座气派的宫殿，还钻研了汉字，给它起了“广寒宫”这个有意思的名字。月亮又怕嫦娥一个人住在宫殿里太寂寞，于是托彗星送来一只兔子。​ 现在万事具备了，月亮便开始日夜期盼嫦娥的到来。他看起来一天比一天圆，一天比一天容光焕发。​ 终于到了约定好的日子，月亮迫不及待地想要迎接嫦娥：他把自己撑得圆鼓鼓的，浑身上下散发出又香又脆的黄光，心想：“嫦娥飞了这么久，一定饿坏了吧。”​ 等了许久，不见人来。月亮累了，再也无法保持饱满，便微微瘪下去一点，但他始终不敢松懈，因为他希望把自己能维持的最好状态展现给嫦娥。​ 又过了几天，嫦娥还是没来。​ 月亮期望着的同时，又有些失望了，于是他从中间分开来：一半继续发出幽光迎接嫦娥，另一半暗自神伤，觉得嫦娥不喜欢他，所以才迟迟不来。​ 后来，月亮有些不满了，把自己缩成一只放久了的香蕉。“反正她不喜欢我，我怎么样都没有关系！”月亮自暴自弃地想。他看起来一点也不美味了。​ 到最后，月亮甚至觉得世界不再需要自己，于是就消失了。“不想来就别来了，永远也别来了！”这算是月亮的临终遗言吧。​ 然而世界是需要月亮的，至少我们的诗人需要他，他还不能就这样消失。所以没过几天，新的月亮又慢慢从黑暗中生出来了。​ 新的月亮是新的，他只记得月中的时候嫦娥会降临，于是他又开始新一轮的期待和失望。​ 今天我见到的月亮是像烂掉的香蕉一样的。接下去一直到中秋，他会一天比一天美味的。" } ]
